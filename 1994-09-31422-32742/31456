Path: msuinfo!netnews.upenn.edu!news.amherst.edu!news.mtholyoke.edu!uhog.mit.edu!europa.eng.gtefsd.com!howland.reston.ans.net!cs.utexas.edu!uunet!senior.nectec.or.th!uwov!john.dehaven
From: john.dehaven@wov.com (John Dehaven)
Newsgroups: sci.crypt
Subject: Re: **VERY FAST 1024BIT R
Date: Wed, 31 Aug 1994 10:46:00 GMT
Message-ID: <9408312111023314@wov.com>
Organization: WOV-Net - BSA Co Ltd
Distribution: world
Lines: 48   


 PR> Usual method is use a small public exponent (3, 17, etc). so
 PR> you don't have to do much multplication.  Then encryption is
 PR> pretty fast on most reasonable computers these days.  You can
 PR> speed up the multiplication with Karatsuba's method (see Knuth
 PR> vol. 2.).  Fancier multiplication methods exist, but don't appear
 PR> to be worthwhile for numbers of this size.

You know this is interesting.  Seems like it *should* be true,
all right.  So I did some experiments with 100-bit exponents.
Both the kinds that stock PGP generates (2^99)+1, or rarely +3
or +5, and also with *random* exponents of this size.  The large
keys appeared to take a bit longer to generate, but that's hard
to tell or measure for sure (other than the need to feed a lot
more keystrokes into the random pool in the case of the random
versions).  There was no obvious *heavy* penalty.

I have one of these 1024-bit experimental keys now; the exponent is

0x 000B 7922 E330 384A BDE3 2982 050D

Or so the results of the key-generation claim.

Using careful timings, I can not measure any conclusive
difference in speed in encrypting or decrypting, as compared to
using a 1024-bit key with the almost-always-default exponent of
17.  These trials were both encrypting and signing
same-key-to-same-key.

Any variance appears to be *way* buried in the normal variations
in runs of a program due to cache loading and so on.  Actually
the variances between different PGP versions doing the same
tasks with the same keys are greater.

I don't guess there is anything goofy about this key either: the
key and messages made with it are usable with PGP versions going
back to 2.3a, and with no evident performance penalty.

Somehow this surprises me, to tell you the truth: I certainly
expected to see differences, and wanted to find out what they
amounted to.  But unless I am doing something very wrong, or PGP
is, why NOT use such large random exponents?  I don't believe
that there is any strong evidence that small exponents or
exponents only very slightly larger than a power of 2 are weaker
than such a random largish exponent, but if it is this cheap and
trouble-free to use such an exponent, I guess I would rather do
that.  Why take an unnecessary risk that someone might someday
get leverage from the small or "more regular" exponents?
