Path: msuinfo!uwm.edu!wupost!micro-heart-of-gold.mit.edu!rutgers!igor.rutgers.edu!zodiac.rutgers.edu!leichter
From: leichter@zodiac.rutgers.edu
Newsgroups: sci.crypt
Subject: Re: Challenging Message
Message-ID: <1993Mar17.085030.1@zodiac.rutgers.edu>
Date: 17 Mar 93 13:50:30 GMT
References: <1993Mar13.111512.2022@altair.selu.edu> <16536@rand.org> <1993Mar13.165350.2027@altair.selu.edu> <1993Mar14.000511.14875@csi.uottawa.ca> <1993Mar14.043418.2037@altair.selu.edu>
Sender: news@igor.rutgers.edu
Organization: Rutgers University Department of Computer Science
Lines: 103
Nntp-Posting-Host: pisces.rutgers.edu

In article <1993Mar14.043418.2037@altair.selu.edu>, fcs$1655@altair.selu.edu
writes:
[Many lines of earlier messages repeated.  Just because the software CAN do
this doesn't mean it's a good idea!]
|    First, I want to thank Jim Gillogly and Christopher Browne for their
| interesting remarks and for the references.  I may be beating a dead
| horse here, but I now can't help wondering what happens when you use
| two words such that the LCM of their lengths is longer than the plaintext.
| So, knowing that that's exactly what I did, using two common words and
| a portion of text from a book, can you decode this rather easily:
| 
|  QELMVVRLIFFQJPAPGHRQBZKCCAGTQYKAHAHKVNUQTLUSSOQFRAZEHIADOSAODNJWJTEAVOHAKPF
| 
Once the LCM is long enough, there are no repetitions, so the problem gets
harder.  What you are approaching is what is known as a "book code":  Rather
than using one or a few key words, use the text of a book starting at some
pre-agreed point.  Book codes can be, and have been, broken.  Think about how
the previous Vigenere examples were borken:  The statistics of English are
very strongly skewed:  "e" is MUCH more common than "w".  A simple substitu-
tion cipher preserves these statistics - it just moves the positions around.
For example, if "e" maps to "d" and "q" to "t", then "d" will be very common
and "t" very rare in the ciphertext.  The statistics are so strong that even
quite small pieces of text are easily broken.  (A human being looking at a
partial decrypt actually uses not just letter statistics, but pair statistics
("h" is quite common after "t") and even higher-order statistics (after "tio",
the next letter is almost certainly "n").  A beyond that, a human can look for
words and even, once some words are there, overall sense.  Many of these
things can be automated.

In a Vigenere ciphertext, the gross statistics are no longer those of English,
but if you group the letters under various assumed key lengths, at the right
guessed key length you'll be looking at a simple substitution, and again the
statistics will jump right out.  Your previous examples were broken by first
guessing the length this way, then using the assumption that the keys were
actually WORDS - a computer with a dictionary (or a human with a lot of time)
can try many words to see which ones produce reasonable decrypts.  Had you
use random strings of letters for your keys, the problem would have been
much harder.

If the "key" is large enough that no repetitions occur, the first-order
attack won't work.  But consider what the statistics of a book code look
like:  "e" encrypted with "e" is much more likely than "q" encrypted with "q".
So the output of a book encrypter also has a characteristic statistical form.
There are many more possibilities to try, but again the fact that the key is
itself English text makes things much easier:  You solve for both key and
plaintext simultaneously (you HAVE to, since they are used symmetrically!)
and anything you learn in either helps with the other.  It takes much more
text, but eventually you can break it.

The "two-word with long LCM" Vigenere is actually harder than a book code in
that the output at each position depends on TWO key letters plus a plaintext
letter - so we are looking at "e" and "e" encrypts "e" versus other triplets.
There are many more combinations, and each time you do this the distribution
gets flatter (how probable is "e" and "q" encrypts "t"?); on the other hand,
there is still some underyling periodicity - you can think of the second
key word as encrypting, not English, but the output of the first encryption,
which has its own regularities.

Breaking a double Vigener like this might require some luck.  On the other
hand, it's 75 letters long, and we know from you that we have as keys TWO
common words the LCM of whose lengths is greater than that.  That probably
means they are 8 or 9 letters each.  How many common English words of that
length are there?  A reasonable attack would be to try them all - not in
pairs, but singly, and then check to see if the result has the right
statistical form for a single-word Vigener.

BTW, a much harder code would be a double book code.  Beyond that is a
triple book code, and so on.  Each additional level smooths out the
underlying statistics somewhat more.  The usual estimate is that each letter
of English text carries, on average, about 2.5 bits of information - that is,
if you blank out one letter in some text, on average there are only about
6 possible choices for that letter that allow the text to be English.  Let's
be careful and assume 2 bits per letter; so every time you use a letter of
English text as a key letter, you are adding about 2 bits of "fuzz" to the
ciphertext.  Now you can see why such codes can be broken:  If we consider
just upper-case letters, each character of ciphertext that you see gives you
around 5 bits of information (if you can find some way to use it), but you've
only "fuzzed away" 2 of those bits with the code.  A two-word Vigenere is
getting closer by "fuzzing away" four bits, but this isn't an accurate measure
since the periodicity of the key adds back more information.  On the other
hand, a triple book code should be adding 6 bits of fuzz, which should mean
there is nothing left for a cryptoanalyst to get his hands on.  (Of course,
this assumes a proper triple book code - three different books, not some
trick like reading the same book three times at three different positions.
The eventual overlaps will leak extra information.  Also, you must NEVER
reuse any portion of the book, or a cryptanalyst will combine your ciphertexts
and use the repetitions against you.  And, yes, this kind of attack been
done successfully.)

If you combine the three books up front to compute a series of key letters,
the "bits of fuzz" argument tells you that the result is a RANDOM series of
letters.  This is the famous "one-time pad", and the resulting system is
usually called a Vernam cipher.  It is absolutely secure, as long as you
never re-use any key material.

|    Incidentally, I found this "Vigenere" in a work about Lewis Carroll.
| Apparently, he used it to send messages to his "Alices".  The author of
| the book seemed to think Carroll had discovered this method himself.
| 
|    Thanks again for any helpful remarks about this kind of stuff.  As you
| can see, I am a complete novice in this area.

							-- Jerry
