Newsgroups: sci.crypt
Path: msuinfo!uwm.edu!cs.utexas.edu!uunet!mcsun!chsun!bernina!nice!gec
From: gec@nice.usergroup.ethz.ch (Germano Caronni)
Subject: Re: Identifying / Securing Files
Message-ID: <1993Mar29.171310.9582@bernina.ethz.ch>
Sender: news@bernina.ethz.ch (USENET News System)
Organization: Swiss Federal Institute of Technology (ETH), Zurich, CH
References: <C4MI2p.57u.1@cs.cmu.edu>
Date: Mon, 29 Mar 1993 17:13:10 GMT
Lines: 141

In article <C4MI2p.57u.1@cs.cmu.edu> Marc.Ringuette@GS80.SP.CS.CMU.EDU writes:
>How about a cryptographic means of making sure that the user of a program
>cannot dissasemble it, and cannot find out any more about the program than
>it's strict i/o mappings?  Or, if communications are available, how about 
>a means of offloading a few computations to the software owner's machine in
>order to prevent dissasembly and/or implement pay-per-use?
>
>I have often heard the claim that there's no such thing as "cryptographically
>strong copy protection", and in fact that the whole idea is silly.  But all
>the evidence I ever get is anecdotes.

Not at all silly, as soon as it gets (commercially) interesting :-)
Ok, I will give you my thoughts, that were behind my 'lightly phrased'
words. (No doubt, they were) But as i am no expert, take this with 
caution :-)


> 1. A program P computes a function f(i) over the integers.
>    The program is expressed in terms of a simple machine language.
>    Does there exist an obfuscating process Obf(P) which produces a
>    new program P' which computes f(i) but guarantees to give away no
>    more information on any single run than the value of f(i)?

P and Obf(P) have to execute in a closed universe, so no network connection
to the vendor...

IMHO It might *somehow* be provable that this is not possible. I am not
good at formal proofs, so let's do it informal...
Obf(P) has to fullfill the same functions as P, so it can be equal to P
or a superset of P.  (of the flow of machine instructions which in their
entity represent P)
Under all circumstances I have *TOTAL* control of the execution of P or
of Obf(P). Whatever mechanism Obf(P) uses to reproduce the functionality
of P I can reproduce too. (I can sample, playback, modify, whatever)
'There aint no such thing as a black box here' as somebody once said :-)
So, by possesing Obf(P) I posses P too. (at least the funtionality of P)

Interesting would be an Process DeObf(P',i) which produces a P'' which does
only work like P for a certain Input i. But then I would posses DeObf(),
and could apply it to any i for a given P' to regain a functionality of P.

Problem here is really that there exists no true black box. The program
has no way to do whatever, which I can not do myself too. (Assuming I have
control over the hardware which executes the Program)

(((
One might think of this whole complex as of the 'secret key encryption'.
The Program represents Key (and algorithm), the input data is the
'cipher' and the ouput is 'plaintext'.
=> No this gets too stupid, Ignore the idea, or what ?
)))


>
> 2. A program P computes a function f(i) over the integers.
>    The user's machine is in constant communications with the
>    software author's machine.  Is it possible to rewrite P
>    so that (a) it requires at least one communication with the
>    author's machine per run, and (b) the amount of communications
>    per run is small, even if i and/or f(i) are large?

Ignore b). Make P reside on the authors machine !
As long as the user can not figure out what P is to deliver, and f(P)
is vital for the correct realization of the algorithm, this should work.
But as soon as the user knows what P is supposd to do, he can make it 
himself, and cut out all the communication parts.
Beside this you will never be able to get 'one communication per run' but
only 'one communication per different input data' if the user is
intelligent enough.
If you need to honour b), you have to split f(), into two parts, which
may well work together to find the result, and make only f2() reside on
the authors machine.

In excess, the whole program would reside by the author (in a secure
environment, not necessarily by the author) , and the user
would only communicate to the Program. This is 'perfect' copy protection,
as there is nothing to copy .-))
(*Yes i mean this as a serious approach, not as a joke!*)

>For case 1, we're looking for some kind of "cryptographically strong
>code shuffler."  I'm imagining some code which munges the input
>unrecognizably, does incomprehensible things to it, and through some
>kind of magic, finally XOR's the answer out of thin air on the last
>instruction of the program...

'thin air' sounds good:-))) 
As stated above, never mind how much input or code! are
munged, as long as i can munge it in the same way, I can 'unmunge' the
answer at the end. (The 'munging' needs to be a symmetric operation, as
all information resides in the program, so no asymetric-key does the
yob) Beside this, how does this help in copy protection ??

>For case 2, we can obviously succeed in requiring communications
>with the author's machine on each run if the entire computation of
>f(i) is offloaded.  But in order to limit the bandwidth of communications 
>between the author and the user, can we concoct a means of offloading
>only a few public-key decryptions (or some such) instead of the entire
>computation?

Hmm.
Distribute communication. (You do not communicate with the author,
but with a regional entity, which is trused by the author, and has a 
copy of f().  (*urgh*)

''Public-Key'':
No way. (At least in my imagination.) What is he supposed to encypt,
decrypt?
But: Does the theme 'Shared control' (see corresponding thread lately
in sci.crpyt) not fit somehow here ? f() shall only work if control
is shared by author and user? Have to think about this :-)


>   2. If you have nit-picks about my question, please suggest fixes
>      rather than just flaming me about it.  These are hard problems
>      to write down in an airtight way.

Watertight is enough for me :-) No, sorry, I have no improvements to make,
but it would be interesting to see a scheme like (1.) above to make
computation of all P''(P',i) to epxensive, and to couple that with a
mechanism which does copy protection. (Don't ask me how, I am out of
Genius Oil(tm) ) So even if we know it is feasible to break the first
presented scheme, make it expensive and impractical.


At least: Don't use copy protections :-)))) <NO comments on this-please!>

Comments are really welcome!

Friendly greetings,

	  Germano Caronni


A last, impractical afterthought.
Just assume, each customer has a different operating system,
and a semantically different set of machine-instructions. The
venodr has to sell just the program-version that runs for the
particular user :-)))
(This does not make impossible copying, but would be a (stupid)
example of making copy-protection ''expensive'' to break.)

