Path: msuinfo!agate!howland.reston.ans.net!europa.eng.gtefsd.com!news.umbc.edu!eff!blanket.mitre.org!linus.mitre.org!linus!mbunix!eachus
From: eachus@spectre.mitre.org (Robert I. Eachus)
Newsgroups: sci.crypt
Subject: Re: Random mappings vs. random permutations (*bonk*)
Date: 19 May 94 11:37:47
Organization: The Mitre Corp., Bedford, MA.
Lines: 97
Message-ID: <EACHUS.94May19113747@spectre.mitre.org>
References: <16FBAF7A6S86.C445585@mizzou1.missouri.edu>
NNTP-Posting-Host: spectre.mitre.org
In-reply-to: C445585@mizzou1.missouri.edu's message of Wed, 18 May 94 17:36:38 CDT

In article <16FBAF7A6S86.C445585@mizzou1.missouri.edu> C445585@mizzou1.missouri.edu writes:

>      Basically, my argument rested on the assumption that a block cipher
>   approximated a random mapping, instead of a random permutation.

   It doesn't approximate a mapping, it IS a one-to-one mapping.
Anyhting else results in either some blocks that cannot be encrypted,
or a block which has more than one decryption.  Now in a mode
where the key changes at each block, the situation is more complex,
but each individual mapping is still one-to-one.

>  The difference is that, with a random mapping, E(X) = E(Y) can
>  happen when X <> Y, but with a random permutation, E(X) = E(Y)
>  guarantees that X = Y.  In other words, a block cipher has to be
>  reversible, so only one input to the block cipher can lead to any
>  specified output of that cipher.

>     Basically, when E() is a block cipher, and you run E() in output-
>  feedback mode to get your PRNG values, the situation is like this...

   Okay, a one-to-one case.  Here is how to do the analysis:

   Each block must be part of a cycle, due to the one-to-one mapping.
(For any block there will be a predecessor and a succesor block, even
if all three are equal--a cycle length of one.)

   What is the expected number of cycles?  Pick a block at random.
Follow the chain until you have a cycle.  This (first) cycle has an
expected length of sum for k equal 1 to 2^n of k*2^-n.  This first
chain has an expected length of (2^n - 1)/2.  But then we have to
compute the expected length of some other chain by choosing a starting
block not in the first chain, and so on until we have accounted for
all blocks.

   (If the mapping is random, what is the expected number of cycles of
length one?  Easy, there are 2^n blocks each of which has a 2^-n chance
of encrypting to itself.  Expectation is one, independent of block size.)

   You should indeed find that the expected number of chains is
2^(n/2), and therefore the average chain size is 2^(n/2), but that is
not the whole story.  What you are really looking for is the expected
length of the chain which includes a block chosen at random.  This is
the same as the length of the first chain above: (2^n - 1)/2.  But
that is STILL not the whole story.  What is the probability that the
IV and key you choose generate a chain shorter than the message to be
encoded?  Oops!   If you care, and are encrypting long messages this
way, compare each block to the first, and if you get a match, select
some other value for the IV.  (This, of course requires storing the IV
with the data.)

  >    I haven't gone and looked up the formula for the expected value
  > of i before I hit a cycle (all my prob/stat books are at home),
  > but I think it will follow a hypergeometric distribution.  2**63
  > looks reasonable, though.

Pretty close.  ;-)

  >     Unless I'm missing something else, if E() were a random *mapping*,
  > we would expect 2**32 cycles.  It looks to me like feeding back one bit
  > at a time, or even 32 bits at a time, would approximate a random mapping,
  > and that it would lead to an expected cycle length of 2**32 or so.  I'm
  > interested in hearing whether or not I'm missing something else here....
  > (This may be where I read about that 2**32 cycle length--I know I read it
  > (or misread it) somewhere.)

   See above.  All these numbers are right, and consistant.  You just
have to notice that the expected length of a cycle including a block
chosen at random is very different from the average cycle length.

  >    One other point: Even though we can talk about expected cycle
  > lengths, we can always get unlucky and hit a really short cycle
  > length.  And with any block cipher with keys that self-decrypt
  > (ie, E(E(x,k0),k0) = x), we'll always get stuck in length 2
  > cycles--E(a,k0) = b, E(b,k0) = a, ...

   Now for the interesting stuff.  We assumed that the mapping is
random.  For any real cipher, like DES it is not.  An interesting
attack on DES (unlike brute force methods so far known) would be to
take some keys, determine all the cycles, and look for patterns.  (And
I said "unlike brute force methods!")  Hmmm.... I can avoid the 64-bit
* 2^64 storage problem by saving only some members of every cycle, for
a straight memory vs. time trade off.  Or I can keep one bit for each
value met, plus the length of the cycles.  2^56 bytes = 7.2 * 10^7
Gigabytes, still out of reach today, but not by much.  OTOH, today you
could either work with 32-bit variations of DES or whatever, or do a
lot of interesting Monte Carlo work.  Determining whether the length
of DES cycles is approximately random certainly seems doable, and has
probably been done.


--

					Robert I. Eachus

with Standard_Disclaimer;
use  Standard_Disclaimer;
function Message (Text: in Clever_Ideas) return Better_Ideas is...
