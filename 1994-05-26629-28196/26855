Path: msuinfo!agate!howland.reston.ans.net!usc!bloom-beacon.mit.edu!ai-lab!kiwi!lethin
From: lethin@kiwi.ai.mit.edu (Rich Lethin)
Newsgroups: sci.math,sci.crypt,alt.security,alt.security.pgp,alt.security.ripem,comp.security.misc,alt.privacy
Subject: Re: Sieve Blocking for MPQS to improve mem-hier locality & performance
Date: 3 May 1994 14:18:33 GMT
Organization: MIT Artificial Intelligence Lab
Lines: 20
Message-ID: <2q5mfpINNbvp@life.ai.mit.edu>
References: <2q3hjp$pqc@linus.mitre.org> <2q40b1INN6q2@life.ai.mit.edu> <2q40pkINN6vr@life.ai.mit.edu> <Cp7FpE.C7t@cwi.nl>
NNTP-Posting-Host: kiwi.ai.mit.edu
Xref: msuinfo sci.math:71139 sci.crypt:26855 alt.security:16335 alt.security.pgp:12421 alt.security.ripem:838 comp.security.misc:9698 alt.privacy:14942

In article <Cp7FpE.C7t@cwi.nl>, Dik T. Winter <dik@cwi.nl> wrote:
:It might be, from a commercial perspective.  Expect a slow down by just
:the factor in access speeds.  Moreover, and this is more essential, you
:only covered bandwith, not latency.  Disk latency will kill it, even if
:you are using 8k disk blocks you may expect at some early stage that each
:access is an access to a different disk block, and than you ought to count
:the net effect of pulling in a single disk block to do an update to a
:single element.

I agree that without any kind of blocking the disk is useless.  With seek
times on the order of 3 msec, random access to update a single word
translates into a bandwidth of 1.3 kbytes/sec.

Don't starting points need to be computed for each factor anyway?  I think
the strongest argument against blocking is that if you simultaneously sieve
K factors you have the algorithmic complexity of choosing the minimum index
from the K-factors in each step.  A naive implementation would do an O(K)
linear scan each time, for a runtime of O((K^2)M) rather than O(KM).  If K
is small, this isn't a big overhead, but you need large K to get any gain
from blocking.
