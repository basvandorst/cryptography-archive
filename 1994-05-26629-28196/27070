Path: msuinfo!agate!usenet.ins.cwru.edu!eff!news.duke.edu!godot.cc.duq.edu!nntp.club.cc.cmu.edu!news.sei.cmu.edu!bb3.andrew.cmu.edu!andrew.cmu.edu!postman+
From: Vincent.Cate@FURMINT.NECTAR.CS.CMU.EDU
Newsgroups: alt.security.pgp,sci.crypt
Subject: Rate of computer progress
Date: Fri, 6 May 94 02:32:31 EDT
Organization: Carnegie Mellon, Pittsburgh, PA
Lines: 150
Message-ID: <Added.QhmSG=u00Udb80hU51@andrew.cmu.edu>
NNTP-Posting-Host: andrew.cmu.edu
Xref: msuinfo alt.security.pgp:12636 sci.crypt:27070


I think the Rivest paper is an excellent paper that everyone interested in 
the RSA algorithm and how hard it is to break should read.

There is one change I would recommend for the next version of such a 
difficulty of factoring paper.

The computer trend has been a doubling in power every 1.5 years for the 
same cost.  I plotted this 8 years ago and we are right where I predicted 
we would be (just dug out the data - see tables below).  So I would use 
this as "average rate of technological progress".   This means that the
"high rate of progress" estimate in this paper is a bit lower than I think 
the "average" estimate should be.  

My old data from 1986:

>Microprocessor   Year       Drystones    "VAX-MIPs"   
>
>4004             1971          4 ?          0.0025   
>8008             1972          7 ?          0.0044  
>8080             1974         36 ?          0.022  
>6502 1 Mhz       1975         37            0.023 
>Z80  2 Mhz       1976         91            0.057
>68000  4 Mhz     1979        692            0.43
>68010 10 Mhz     1983       1156            0.72   
>80286  5 Mhz     1983       1428            0.89  
>68020 16 Mhz     1985       4504            2.82 
>68020 25 Mhz     1986       6750 ?          4.22
>80386 16 Mhz     1986       5801            3.6
>MIPS  12 Mhz     1986      12000            7.5 
>
>Assume:  MIPs = Drystones / 1600.
>    This comes from a VAX MIP being the standard MIP, and a
>VAX MIP being about 1600 drystones.
>
>    The drystones for the 4004, 8008, and 8080 were estimated
>by comparing the time to add two 8 bit numbers with the
>time for a Z80 and scaling the Z80 drystones.

1994-1971 = 23            years since first CPU (4004)
23/1.5 = 15.33333         number of doubling
2^15.33 = 41285           increase in CPU power
0.0025*41285 = 103.2      expected VAX equivalents on a CPU for 1994

Bingo!!!  A 100 MHZ Pentium or 100 Mhz PowerPC are each 100 times a VAX.  

Using the double in 1.5 years rule starting from a few other points:
  8080  in 1974 --> 227x VAX  (8080 chip was $500 in 1974 dollars!)
  68010 in 1983 --> 116x VAX  (about right)
  MIPS  in 1986 --> 295x VAX  (but MIPS was workstation not PC)

Today there are 200 Mhz Alpha PCs ($6,000) that are 200x VAX.
I believe there will be 200 Mhz Alphas for only $3,000 by the end 
of the year.

The trend really goes back further.  From the IBM 650 in 1956 to 
the IBM 370/168 in 1972 IBM mainframes went from 0.001 MIPS to 2.3 MIPS 
with the same doubling time of 1.5 years.  Probably after the 68000
in 1979 micros had a lower cost/MIP than mainframes, as about that
time mainframes did not keep up their doubling rate.  So the "best
mips/$ trend" is really a 38 year trend of doubling every 1.5 years.

>System     Date    MIPs  CPUs IBM-MIPs/CPU   
>650        9/56               0.001    
>7070       9/58               0.022   
>1401      10/59               0.0074 
>1410      10/62               0.0154
>360/50     4/64               0.178
>360/65     4/65               0.68
>360/85     1/68               2.4
>370/165    6/70               1.89   
>370/168    8/72               2.3   
>370/168-3  3/75               2.7  
>3033       3/77               4.7 
>3081-K    10/81    13.5   2   6.75  
>3090/200   2/85    28.0   2  14.0
>
>Datamation May 1985 page 90.
>Datamation Feb 1984 page 164.


Predicting the future is always hard.  There are reasons to expect 
things to progress faster (current chips are only 2D planes of 
transistors - once they go 3D doubling times will be shorter 
(transistors in 1 cubic-centimeter goes up with 3rd power of size 
while transistors on 1 sq-centimeter goes up with 2nd power of size)).  
The doubling time could stay the same (it is a 23 or 38 year trend).
Or the doubling time could slow down (as chip features get very small 
it gets harder to cut the size by 30%).  All in all, I think the best 
bet is that the doubling in 1.5 years rule will keep on working.

Anyone is welcome to copy this or reference it.  I already sent a
copy to both Rivest and Bidzos.  Please send me a copy if you have
a table of ship dates for CPUs since 1986 (I probably have VAX-MIPS).

Many people noticed the performance trend before I did.  The 3D comment 
is my own.

-------------------------------------------------------------------


Also good to put in such a paper is something like the following from
the RSA FAQ in ftp://rsa.com/faq:

>As for the slowdown caused by increasing the key size (see Question
>2.3), doubling the modulus length would, on average, increase the
>time required for public-key operations (encryption and signature
>verification) by a factor of 4, and increase the time taken by private
>key operations (decryption and signing) by a factor of 8. The reason that
>public-key operations are affected less than private-key operations is that
>the public exponent can remain fixed when the modulus is increased, whereas
>the private exponent increases proportionally. Key generation time would
>increase by a factor of 16 upon doubling the modulus, but this is a
>relatively infrequent operation for most users.

The point is that going from 250 digits to 500 digits makes RSA 
encryption take only 4 times as long, while breaking 500 digits takes 
around the square of the number of operations (say going from 10^10 to 
10^20 operations).  Clearly, faster computers help encryption far more 
than code breaking.  Computer progress helps privacy.  In 3 years we
will have another factor of 4 in computing power and can double our
key sizes with the same performance, while the factor of 4 only 
lets people factor numbers with a few more digits than they can 
currently factor.  So even if most of the keys in use today could be 
broken within 30 years, 3 years from now most keys in use would take 
more than 100 years to break.  Strong crypto is here.

Also, RSA is only needed for sending the private key session keys.  
For private key algorithms, the performance does not need to drop off 
much at all with key size.  For example, Terry Ritter (ritter@io.com) 
has a method that uses 4 sets of DES to get a key size 4 times as large 
and only spend 1.2 times a much computation per byte.

The net result is that programs like PGP do not really run much slower 
even with 1,300 bit key sizes.  If a few constants were changed, PGP
would probably be fine at 5,000 bits or more.  Currently PGP uses IDEA
for the session encryption, which can not scale keysizes.  But that 
should change with time.


-------------------------------------------------------------------

---  Vince Cate
     vac@cs.cmu.edu
     5/5/94

Master copy of this file:

     ftp://furmint.nectar.cs.cmu.edu/security/rate-of-computer-progress

