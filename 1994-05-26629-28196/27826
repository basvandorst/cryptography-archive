Path: msuinfo!agate!howland.reston.ans.net!cs.utexas.edu!not-for-mail
From: ritter@indial1.io.com (Terry Ritter)
Newsgroups: sci.crypt
Subject: Re: Announcement: Mac Crypto Interface Project
Date: 21 May 1994 14:46:03 -0500
Organization: UTexas Mail-to-News Gateway
Lines: 260
Sender: nobody@cs.utexas.edu
Message-ID: <199405211944.OAA02097@indial1.io.com>
NNTP-Posting-Host: news.cs.utexas.edu

 In <2rf8p3$db@access1.digex.net> unicorn@access1.digex.net (Black
 Unicorn) writes:


>> Verification *is* a cryptographic question:  Without verification,
>> there is no cryptographic relationship, despite the use of public-
>> key technology.
>
>True, but verification and initial certification are two matters.

 If you take different meanings for these, you will have to be
 considerably more forthcoming than this.  In this discussion I have
 been using both terms to represent the same issue.

 In fact, trying to think how they might be different brings out the
 point that a single "certification" is not sufficient.  The original
 public key may have been compromised (possibly a trusted employee
 left) and so might have been changed.  The Opponent may *have* the
 compromised key.  Certification is a continuous process.


>> With regard to the "trusted key signature," note that even if we
>> trust the final provider, there may be an informant who has
>> inserted a false key somewhere up the line.  This would be a
>> "single point failure" which I would call an unacceptable risk.
>
>My definition of "Trusted key signature" is that the signature is from a
>party you trust to sign keys.  Note that if you can estlablish that the
>key belongs to who it SAYS it does, that is verification.  The discovery
>of an informant is really a non-protocol question when you're dealing in
>this context.

 To the extent that keys are not directly attested-to but instead
 certified by a friend-of-a-friend-of-a-friend, the most-recent
 friend can be as trustworthy as one could hope for, and the
 protocol could still deliver a false key from an informant.

 In the beginning, PGP had a strange sort of "voting" protocol where
 the user assigned "trust" probabilities to certifications from
 various sources--as far as I know, it still does.  But this protocol
 is useless if all the direct certifications happen to depend on a
 single false original source, and the protocol is not built to be
 able to identify that situation.  This particular issue is what I
 intended "single point failure" to imply here.  If a widely-trusted
 informant provides false keys for various people, the PGP protocol
 will not detect it, and will not indicate that the various "votes"
 are not really independent.


>You seem to be most worried about a man in the middle problem.

 I am worried about this problem because it seems to be the major
 remaining weakness in the overall system.  It is far, far more
 likely than direct technical attacks on RSA or IDEA keys.


>If you
>have made sure that you have THE KEY that THE RECIPIENT gave you, then
>the man in the middle problem is gone.

 Sure, but how is one to do that?

 First, many keys come from secondary sources and not direct from
 the recipient.  Can we trust the original certification?  Can we
 trust the repository?

 Second, the recipient is often remote.  Since the network cannot
 be trusted (or else we would not need cryptography anyway), we
 cannot trust a key which is delivered by the network . . . unless,
 of course, it is delivered under a real cryptographic protocol.


>If I have made a proper exchange of keys with joe blow, and he sends me a
>message signed with his key, or I send him a note encrypted with his key,
>there are only a few posibilited of compromise.
>
>1>  joe blow's key is compromised.
>2>  Public key crypto is broken.

 Everything depends upon this "proper exchange of keys."  Public key
 signatures do not help the situation until *after* a key has been
 certified.

 The problem is that people get keys from the network, from servers,
 from friends, and not directly from the original source.  The
 purpose of a true cryptographic certification protocol would be to
 support key distribution through secondary sources.  Failure to have
 such a protocol means that anyone who uses a key from a secondary
 source is using an essentially insecure system.


>> Clearly, an informant gets to be an effective informant to the
>> extent s/he is trusted by the sheep.  All that is necessary is to
>> be an "early," "well known" or "intimidated" personage, and you
>> can sweep up vast numbers of believing users with your perfidy.
>
>How is this a question of cryptography?
>Even a one time pad system is vunerable to this problem.

 Not really.  Any secret-key system has a straightforward protocol:
 "transfer keys directly in absolute secrecy."  This may be awkward,
 but it certainly is not hard to understand.

 The problem with public-key systems is that public keys do not
 carry the automatic certification that secret keys do.  Of course,
 if you get a public key directly from the originator, there still
 is no problem.  The problem occurs when public keys are distributed
 through insecure systems and people.  Without a real cryptographic
 certification protocol, a spoofer can offer a false key, and this
 will almost never be noticed.


>> I find it hard to believe that any cryptosystem based on third-
>> party human "trust" could possibly be called a cryptosystem.  Just
>> how much money or intimidation would it take to "turn" a normal
>> net-person?  How does this compare with the investment and time
>> needed to attack a key?
>
>Then by your definition, every cryptosystem is not a cryptosystem.

 I do have to "trust" the cryptosystem design and implementation, but
 that is not the issue here.  To a large extent I have to "trust" the
 person on the other end, but that "trust" is limited by reality if
 nobody else knows the secret I send.  If the secret gets out, I void
 that trust and go on with my life.  (Others might have a different
 response, of course.)


>How do I know that the President is really on the other end of the phone?

 This is some other problem.  The problem I have been discussing is
 that, *even if you do* know it is the President on the other end,
 how do you know that someone else is not listening in?


>How do I know that my life long friend is betraying me?

 This is also not the problem I have been discussing.  However,
 if only you and s/he know the secret, and it gets out, at least you
 know what happened, IF the cryptosystem was secure.  In some sense
 we need less "trust" for the far end if we have a secure system.


>How can you possibly expect a cryptosystem to solve these problems?

 I don't.


>You can have the strongest cryptosystem in the world, but if your sending
>to your friend who is forwarding to bob, then you are compromised.

 Naturally.


>I don't understand how this is a cryptographic problem.  You are blurring
>the questions of trust in persons, and crypto.

 If I am blurring them, then you are not seeing the distinctions.

 The issue is that when public keys are distributed freely--as one
 might do because, after all, public keys are, well, PUBLIC--then
 one can get a false key made by a spoofer.  If we use a spoofed
 key (and the spoofer cooperates by forwarding our messages), we
 still get to talk to the far end, but we do so insecurely.  It seems
 odd to me that we would go to all the trouble of using a system
 which should be secure against a thousand years of computer time
 used attacking the keys, but which is vulnerable to a quite modest
 spoofing investment.  Again, I note that the very routing and
 re-routing that makes The Network so useful is exactly the sort of
 thing which could provide direct support for spoofing.


>> On the other hand, the relationship between me and the intended
>> recipient is not simply an empty "trust" if the cryptosystem is
>> secure:  If secret information gets out, we will *both* know who
>> is responsible.  This is about all we can expect from a secret,
>> but can we even say this if we have a weak cryptosystem?
>
>How is it that this cannot happen to a "secure system"

 Well, that is what a secure system buys.  It buys the ability to
 communicate a secret.  It does not buy the ability to trust the
 person who gets the secret.  But it should buy the ability to know
 that if that secret got out, the other person did it.


>If messages are unreadable without the key, then anyone with the key can
>read it.  How can you make a key personal to every person and
>uncompromisable?

 Does this relate to the discussion?

 Again, if the far end has a deciphering key and gives it away to
 others, others can read the message, but this is just the same as
 deciphering the message first and giving it away.  Cryptography does
 not address this.  Instead, cryptography addresses the case that
 the far end *does not* give away the key *or* the information, and
 The Opponent tries to gain the information in transit.  This can
 be done if The Opponent is a spoofer and "public" keys are not
 obtained directly, but are instead distributed without a
 cryptographic protocol, and this is the widespread current
 situation.  A successful spoofer can obtain information even if
 trust for the far end is justified.


>> I think that a public-key cryptosystem should have a true
>> cryptographic protocol for key validation.  Absent that, it should
>> force at least a minimal manual validation before using any public
>> key, or state that it only becomes a serious cryptosystem when used
>> by crypto-trained operators.
>
>It's a serious crypto system whatever is done.

 I disagree.  I think the cryptosystem is IDEA, RSA, key-delivery,
 key-storage, and every other thing about the system.  To the extent
 that any part of it is insecure, the system is to that extent
 insecure.  Here we have the example of a cryptosystem which does
 not have certified key-delivery.  Thus, if the user is not an
 expert in the user of such cryptography, it is quite likely that
 the system will be used with insecure keys and be, thus, insecure.


>Your confusing the trust in the data with the trust of the source of that
>data.  If a key is signed, and RSA/MD5/IDEA is not broken, then the only
>question to ask is "how much to I trust the PERSON who made the signature?"

 Nope.  Signing does not help here.  The Opponent can sign his or
 her keys just as well, and how would we know the difference?
 Signing only helps *after* a key is certified.  The issue is the
 absolute cryptographic certification of the original key, and some
 public-key systems do this, while others leave it to the user.

 But if someone uses such a system, don't they expect that their
 communications will be secure?  Otherwise why use the system?  But
 if the system requires the services of an expert user to make sure
 it is secure, should unsophisticated users be encouraged to use it?


>I would never want to use a cryptosystem that insists on certain methods
>to certify keys.

 Key-distribution is a part of cryptography.  To the extent that it
 is weak, the cryptosystem is weak.


>You want the program to do all the work for you.
>I don't see how it can.

 No.  I want a cryptographic system to provide what it can, and
 clearly disclaim what it does not provide.  A public-key system
 without a strong cryptographic protocol for key-certification
 cannot be relied upon as a secure link.  Such a system is only
 secure to the extent that there is a competent crypto operator
 who will not use the system without certifying the key.  To what
 extent do you suppose this is done today?

 ---
 Terry Ritter   ritter@io.com


