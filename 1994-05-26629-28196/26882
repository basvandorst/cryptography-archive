Path: msuinfo!agate!news.ossi.com!ihnp4.ucsd.edu!news.cerf.net!mvb.saic.com!MathWorks.Com!europa.eng.gtefsd.com!howland.reston.ans.net!newsserver.jvnc.net!igor.rutgers.edu!thorium.rutgers.edu!leichter
From: leichter@thorium.rutgers.edu
Newsgroups: comp.security.misc,alt.security,sci.crypt,alt.2600
Subject: Re: Jitec claim world's first virus-proof computer
Message-ID: <1994May3.163024.1@thorium.rutgers.edu>
Date: 3 May 94 21:30:24 GMT
References: <2o3q7s$319@bmerha64.bnr.ca> <FAIGIN.94Apr8092012@solarium.aero.org> <FAIGIN.94Apr14081828@soldan.aero.org> <2olsn6$jb5@rzsun02.rrz.uni-hamburg.de> <1994Apr25.122529.1@thorium.rutgers.edu> <2ph5on$9lp@rzsun02.rrz.uni-hamburg.de>
Sender: news@igor.rutgers.edu
Followup-To: comp.security.misc
Lines: 179
Nntp-Posting-Host: thorium.rutgers.edu
Xref: msuinfo comp.security.misc:9716 alt.security:16362 sci.crypt:26882 alt.2600:8455

> In article <2ph5on$9lp@rzsun02.rrz.uni-hamburg.de>,
> bontchev@fbihh.informatik.uni-hamburg.de (Vesselin Bontchev) writes:
| leichter@thorium.rutgers.edu (leichter@thorium.rutgers.edu) writes:
| 
|| Suppose that the rules were the following:  No executing program may either
|| (a) write to a file that has x permission for anyone; or (b) chmod any file
|| to add x permission for anyone unless the owner of the executing program is
|| (1) the same as the owner of the file being changed or (2) root.
| 
| Stoopid qvesion No. 1: how do you compile programs on such a system?
| 
| If the answer is "you don't, only root does", then this is not a
| general-purpose system, I mean one that people would actually *use*.
| 
| If the answer is "the compiler is SUID (or the equivalent)",

You didn't read what I wrote.  The compiler is *owned* by root, hence in this
allowed to create executable files for anyone.  You can create your own
private compiler and use it to create your own executable files.  However, *no
one else can use your compiler*.  To make the compiler actually directly
usable by anyone else, either they'd have to be willing to copy it and then
mark it executable, or it would have to be marked as "trusted", which in my
simplified model translates to "is owned by root".

|							       then here
| is
| 
| Stoopid qvestion No. 2: how do you prevent a virus from outputting its
| source in a file, calling the compiler to compile it, then executing
| the resulting executable and so on? (or the many alternative
| approaches, like renaming an existing executable and so on.)
| 
I wasn't attempting to produce a complete description.  Grafting a new
security model onto something with as open and general a semantics as Unix
is extremely difficult.  I gave a small approximation to such a model by
looking at file ownership.  It is absolutely true that any such mechanism
can be subverted by simply creating a new process.  However, that's not a
fundamental objection.

The point of the model I'm suggesting is that a process may carry "the mark
of Cain" if it is running untrusted code, where untrusted means "neither
created by the owner of the process, nor marked as trusted by root".  A
"marked" process is not allowed to modify or create executables.  If the
"mark" is automatically applied to any process is creates - i.e., it is
part of the information carried along by fork() - and if, further, the mark
once turned on cannot be turned off, even by running an otherwise-trusted
program, then you produce the "limited transitivity" effect I'm getting at.

Again, I don't claim what I've described is nearly enough for so general a
system as Unix.  You'd have to examine every single system operation to see
how it interacts with the "mark of Cain".  And you'd probably want to add
other features to prevent more indirect breakins.  (For example, a virus
could try to modify your .login or equivalent.  Marking such files executable
would allow the protection mechanism to keep them safe.  If shells refused to 
execute scripts that were not marked executable, ever, people would have a
strong self interest in making their scripts secure.)

|| The exception
|| clauses are (2) for trusted programs (particularly the linker);
| 
| Aha, so the something that turns sources into executables must be
| SUID. Just as I expected.

No.  Again, read what I wrote.  What's special about the linker is that
it's *owned* by root, that that it *runs as* root.

| 
|| or (1) for
|| changing your own files any way you like.
| 
| Yep. Too bad that when Bob runs Alice's infected program, this results
| in the virus (running with Bob's privileges) creating a source of
| itself (or copying it from Alice's directory, but the self-writing
| programs are so cute that I just couldn't resist), compiling it with the 
| SUID compiler/assembler/loader, and then executing it (still with Bob's 
| privileges), thus infecting all of Bob's files.

You're repeating yourself.  I won't bother to repeat myself in response.

| 
|| Under this semantics, when Bob runs Alice's infected program, the program
|| is free to infect any of Alice's files - nothing new here, Alice could have
|| infected her own files herself. 
| 
| Not really. When Bob runs Alice's virus, the virus runs with Bob's
| privileges, and as funny as it is, *cannot* infect any of Alice's
| programs. It can infect only Bob's, well, calling the compiler as a
| middle step, if you use the improvements suggested by you.
| 
|| What it comes down to is that very few programs really need to create
|| executable files, almost none need to modify them - and one multi-user
|| systems, the exceptions that involve creating or modifying *another
|| user's* executable files are so rare that one can probably forbid them
|| without causing undue harm.
| 
| Let's see... As a minimum, you need the linker (or you cannot compile
| programs), the librarian (or a virus may infect the libraries), the
| file manager (cp and all that jazz)...
Neither the librarian nor cp and similar programs is in the least bit
relevent here.  The issue with the librarian is a subset of the fact that
a virus could, in principle, infect not executable files but object files
it finds around - or, for that matter sources.  Absolutely true.  However,
executable files are a hell of a lot easier to infect, since you *know*
what to look for and how they come into execution.  Infecting sources would
be extremely difficult - you'd have to figure out what they are doing if you
wanted any significant chance of modifying them without breaking them.
Infecting object files would be easier, but still would require quite a bit
more sophistication than just attacking executables.  And also more luck -
typical directories don't have many object files lying around.  This is likely
to make the virus infect very slowly.

Of course, I suppose you could have the linker require that .o files be
marked executable so that they fall under the same protection mechanism.

As I said myself later in my message, there are always attacks.  The point is
not to prove you've eliminated them all - it's to make them much harder.

|					 This idea reminds me of
| something I read in a paper by Maria Pozzo, long time ago. The idea
| was that you allow only to a few programs to modify/create executable
| code and only if (a) they *create* it (as opposed to modifying
| existing code) or (b) the names of the files containing it are
| specified as arguments on the command line when invoking the program.
| I remember that the idea was rejected as not good enough to stop
| viruses, but I don't remember any more why... Probably will have to
| re-read that paper...
| 
This is a different idea.

|| The result would be a system in which viruses could certainly spread as
|| much as they liked within one person's files, but since the transitive
|| closure of *executable* files writable by that person would be just that
|| person's files, it could go no further.
| 
| Ah, yes, if you can achieve that (limiting the trnasitivity of the
| information flow) - you have stopped the virus. However, such systems
| tend to be either highly specialized or completely unusable (or both),
| and I don't think that the solution proposed by you achieves it.
| 
|| Of course, no protection is absolute. 
| 
| Well, the OFF switch works pretty well... :-) Sorry, couldn't resist.
| 
|| (Ultimately, Alice might have hidden the virus in the source code and
|| induced Bob to re-compile it himself!) 
| 
| Yep, that's what I meant, although in somehow more elaborated form.
| 
|| But one can still do a hell of a lot better than we are
|| doing today.
| 
| One sure can. Even an out-of-the-box Un*x-ish system that has as many
| holes as Swiss cheese can be much more virus-resitent than MessyDOS.
| I was just trying to point out that viruses under such systems (and
| even on much better protected ones) are still possible

We don't disagree here.  In fact, existing mechanisms on even fairly secure
systems do almost nothing to block viruses today (though in fact Unix *does*
provide what is, in effect, an absolutely foolproof virus *detection*
mechanism:  The time-of-last-inode-modification field for a file - given by
ls -c - cannot be changed, even by root (though of course root could reset
the system time, touch the file, then put the system time back again).  If
you keep track of this time for all your executables, and check it periodi-
cally, you'll know when any of your executables is changed.  Of course,
you'll have to sort out the noise of changes because you moved the file
and such like stuff... not a trivial thing, if you are an active developer.

|							 (something that
| many non-MessyDOS users tend to forget) and that while you can do a
| lot to make the problem easier to handle, you still cannot solve it
| completely, without making the system unusable.
| 
| Other than that, and to return to the original subject that started
| this (longish) tread - anybody who is marketing "virus-proof
| computers" is almost certainly selling snake oil, unless they are of
| the kind that you put in the microwave owens. :-)
| 
Here, I agree with you absolutely.
							-- Jerry
