Path: msuinfo!netnews.upenn.edu!news.cc.swarthmore.edu!psuvax1!news.pop.psu.edu!news.cac.psu.edu!howland.reston.ans.net!europa.eng.gtefsd.com!MathWorks.Com!yeshua.marcam.com!charnel.ecst.csuchico.edu!xmission!xmission!not-for-mail
From: berzerk@xmission.com (Berzerk)
Newsgroups: sci.crypt
Subject: Re: Detecting Encrytion
Date: 11 Jul 1994 17:28:17 -0600
Organization: XMission Public Access Internet (801-539-0900)
Lines: 22
Distribution: world
Message-ID: <2vskih$155@xmission.xmission.com>
NNTP-Posting-Host: xmission
X-Newsreader: TIN [version 1.2 PL2]

Here is how I would do it.

Zero, don't include "giveaways" like "begin pgp ..." etc, and un uuencode 
uuencoded files.

First, take a population count.  If the number of standard deviations 
from a random sequence is greater than some cutoff, throw it out.
You could make hardware to do this on the sequence, and its diferential 
easily.  I think the vast majority of files will not fit this.

Second, do specific filters, generated from having people look at what 
gets through the first filter, but is still a gif file, a file from an 
instrument, or something with characteristics like that.

This suggests that simply padding a message with lots of zeros or adding 
non-random repetative data would escape this simple test.  Any 
stenographic method would do, unless the data was first "un steno.exe"ed.

at some level, looking at 64 bit autocorilations for DES and IDEA will 
show something, even with feedback.

Berzerk.
