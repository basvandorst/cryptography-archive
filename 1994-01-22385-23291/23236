Newsgroups: sci.crypt
Path: msuinfo!agate!library.ucla.edu!europa.eng.gtefsd.com!howland.reston.ans.net!usc!elroy.jpl.nasa.gov!decwrl!netcomsv!netcom.com!browe
From: browe@netcom.com (William Rowe)
Subject: Re: Nuclear random number generator
Message-ID: <broweCKBpE4.LyE@netcom.com>
Organization: NETCOM On-line Communication Services (408 241-9760 guest)
References: <broweCK81CL.6EE@netcom.com> <phrCK893q.4wG@netcom.com> <broweCK9uKp.35n@netcom.com> <phrCKA5yK.6F0@netcom.com>
Date: Fri, 28 Jan 1994 04:49:16 GMT
Lines: 15

phr@netcom.com (Paul Rubin) writes:

>Well given any probability distribution you can compute the 
>information entropy = - sum (log (P_i)) where the P_i's are
>the probabilities of each number appearing.  This is probably
>the quantity you're interested in for cryptographic purposes.
>It is maximized when all numbers are equally probable.

Good point. I hadn't really thought of it that way. This clearly implies
an uniform distribution is optimal, but are other distributions adequate?

-- 
_______________________________________________________________________________
William Rowe                                                   browe@netcom.com
MD5OfPublicKey: F29A99C805B41838D9240AEE28EBF383         ghostbit@well.sf.ca.us
