Path: msuinfo!agate!howland.reston.ans.net!europa.eng.gtefsd.com!MathWorks.Com!zombie.ncsc.mil!golf!mizzou1.missouri.edu!C445585
From: C445585@mizzou1.missouri.edu
Newsgroups: sci.crypt
Subject: Encryption from hash functions
Date: Sun, 27 Mar 94 17:46:38 CST
Organization: University of Missouri, Columbia
Lines: 53
Message-ID: <16F86FA00S86.C445585@mizzou1.missouri.edu>
References: <jgfoot-250394111511@silliman-college-kstar-node.net.yale.edu> <WCS.94Mar27042724@anchor.att.com> <CnCF8B.C8H@cnsnews.Colorado.EDU> <16F86EA72S86.C445585@mizzou1.missouri.edu>
NNTP-Posting-Host: mizzou1.missouri.edu

 
   If we're going to try to design encryption schemes based on one-way
hash functions, I think it's important to base the security of our encryption
on the security of the hash function--so that we can use the efforts of the
designers and everyone who's unsuccessfully attacked the hash function to
assure us that our encryption scheme is strong.  Otherwise, why not just
design your own encryption scheme from scratch?
 
   There are two basic kinds of attacks against one-way hashes:  Target
and Collision attacks.  In a really good article in Eurocrypt '92, Lai
and Massey discuss several successful attacks on one-way hashes based on
block ciphers.  ("Hash Functions Based on Block Ciphers," I think.)  I'm
taking some of my terms from them....
 
   The hash functions that are currently most used seem to be MD5 and SHA
and some other outgrowths of MD4.  Those (and most other hash functions
I'm aware of) consist of three steps to hash a message.  First, they
pad the message out, then the append the length of the message, and
then, they apply a compression function to each fixed-sized block of the
padded message.  For MD5 and SHA, the compression function is something
like F(X,M) where X is the value of the hash, up until now, and M is the
next fixed-length message block.  After each application of the message
block, each 32-bit word of F(X,M)'s output is added to the previous hash
value, forming the new hash value.  We're almost always relying on the
strength of the compression function alone, when we're dealing with
encrypting data.  The general format seems to be something like
   Ciphertext = Plaintext XOR F(key-derived bits, key-derived bits)
 
   MDC uses
   Ciphertext = Plaintext XOR F(Previous Ciphertext, Expanded Key)
 
   Although it doesn't look too easy to retrieve the Expanded Key from
the output, I don't see how the ability to do so would allow an attacker
to find two messages that collided in the hash function, as a general rule.
This is because, after two or three times of getting
F(X,M) for different X's but the same M, we've basically ruled out
all but one possible M.  (I'm assuming that F() mostly acts like a random
mapping from (say) 672 bits to (say) 160 bits.)  In a chosen ciphertext
attack, the attacker gets to *choose* which X's will be fed into the
F() function.  This suggests a couple design principles for encryption
schemes based on one-way hashes:
 
1.  The attacker shouldn't be able to choose X or M for a compression
    function's input directly, if she's going to be getting the output
    from that function directly.
 
2.  The X and M values should change for each block encrypted to some
    extent, based on the key.  I'd like to see them both hidden from the
    attacker in some way.
 
   Any comments or further ideas?
 
   --John Kelsey, c445585@mizzou1.missouri.edu
