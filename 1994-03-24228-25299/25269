Newsgroups: sci.crypt
Path: msuinfo!netnews.upenn.edu!dsinc!birdie-blue.cis.pitt.edu!gatech!swrinde!cs.utexas.edu!howland.reston.ans.net!pipex!ibmpcug!ibmpcug!exnet!dcs.ed.ac.uk!pdc
From: pdc@dcs.ed.ac.uk (Paul Crowley)
Subject: Hard instances
Message-ID: <CnGzvF.D5E@dcs.ed.ac.uk>
Sender: cnews@dcs.ed.ac.uk (UseNet News Admin)
Organization: Edinburgh University
References: <1994Mar28.110102.9143@martha.utcc.utk.edu> <2n7fkv$ppa@access1.digex.net> <EACHUS.94Mar29142111@spectre.mitre.org>
Distribution: inet
Date: Wed, 30 Mar 1994 09:04:26 GMT
Lines: 22

Quoting eachus@spectre.mitre.org (Robert I. Eachus) in article <EACHUS.94Mar29142111@spectre.mitre.org>:
>   A better statement might be that not all instances of the knapsack
>problem are hard (in fact most are easy)

There's something that worries me.  Is there a theoretical basis by
which I might be able to rate *instances* of a problem as "easy" or
"hard"?  For every instance of a problem, there is a program that finds
the solution in polynomial time; it consists of a large printf()
statement.  Most instances of factorisation are easy, so even if we
prove that factorisation is in ~P, we still won't know if the
factorisations needed to break RSA will always take exponential time.

Perhaps what we need is a proof based on the random way in which RSA
prime-pairs is generated.  Something along the lines of "For any
factorisation algorithm, the expected time to factorise an N generated
in this way increases exponentially with the length of N" or some such.

Of course, all this assumes theory we're nowhere near, since we don't
even have P!=NP...
  __                                  _____
\/ o\ Paul Crowley   pdc@dcs.ed.ac.uk \\ // 42A47697 54144EA4 BACFA9FD C9433347
/\__/ Trust me. I know what I'm doing. \X/  WWW: http://tardis.ed.ac.uk/~pdc/
