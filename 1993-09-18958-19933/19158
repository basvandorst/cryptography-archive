Newsgroups: sci.crypt
Path: msuinfo!uwm.edu!cs.utexas.edu!swrinde!elroy.jpl.nasa.gov!ames!sgi!wdl1!nebula!koontzd
From: koontzd@nebula.lrcs.loral.com (David Koontz )
Subject: Efficient DES Key Search, Micheal J. Wiener
Message-ID: <1993Sep8.225938.13675@wdl.loral.com>
Originator: koontzd@nebula
Keywords:  DES, keys, money
Sender: news@wdl.loral.com
Organization: Loral Rolm Computer Systems
Date: Wed, 8 Sep 1993 22:59:38 GMT
Lines: 59

I just read Micheal J. Wieners' paper that was presented at CRYPTO 93.
John Gilmore deposited it on ftp.eff.org:/pub/EFF/crupto/des_key_search.ps,
right before my very eyes.

I have posted on the net about pipelined DES chips for attacks before.  I 
believe it to be possible to run a bit faster than the 50 MHz he used, 
may upto 75 MHz, I had first talked about 1.25 um CMOS pipelined DES
with a 40 MHz clock.  I had done some back of an envelope figuring and came
up with a gate count 3 times higher, the big difference in the S boxes and
perhaps also accounted by using numbers for enabled registers.  The other
major difference is that I envisioned simply piping the 56 bit key, and 
having 16 unique sets of 48 bit tap offs for each stage.   These are
easy to describe and can be found in a table in the Mayers-Metyas book
on Cryptography.  Describing left shifts is more compact, probably.

I think the development time/cost is a bit skewed, with the cost about
right.  My concern would be design verification, you would want to write
a behavior of this at some point (C or VHDL or Verilog HDL).  When writing
DES code that is essential transformed and abstracted for performance, I
found it nice to be able to generate common formatted data from a known
good implementation for comparision, including between rounds.  You just
MIGHT have to trouble shoot the design.

Anyway, the level of detail in the paper is impressive, even forecasting
failure rates, although cost of repair and spares wasn't included in the
cost of the system he describes.  The use of a polynomial for the key counter
was nice, although I have no idea how you figure distance for starting values
to prevent overlap between chips.

Having just re-read "Seizing the Enigma" again recently, and with respect
to the 'bombes', I was wondering about the distinction between soft errors 
and hard errors.  The mechanical monstrousities used to search for enigma
keys had a higher failure rate than M. Wieners' system figured in runtime.  

One could imagine spending years running diagnostics.  Failures could be
classed as either catestrophic or match failure.  A failure is suspected
after missing a match in the test interval time (4 or 8 hours).  Basic
diagnostics are run, which would show dead chips (including processors).
If nothing is found, possibly the best thing would be to reconfigure the
key search chips key space.  If a match is subsequently found, the matchee
points to the previous match failure.  This finds both soft errors and
the hard errors that are caused by data pattern sensitivity in a marginal
chip.  As longs as key search matches are found there is no error that
needs correcting.  It would behoove the host (PC) to double check the
results, for the case of false matches, while leaving the key search
machine running.  Statistics should be gathered, including data/ciphertext
and key search space on failures.  While were at it the found keys should
be tracked for correlation.

The processors sound awful wimpy in terms of RAM and ROM.

It would be a fun project to build, anyone know of someone with a half
million dollars to spend?  A couple of years ago I almost had the enough
money to do a pipeline DES chip, but my wife wouldn't go along with it.
(I'm talking NRE, the rest would have used stolen cycles at my then work).

I remember seeing a piece of crypto in 1978 that was block product cipher
and ran in excess of 100 Mbits/sec, in LSI.  It might be appropriate to
worry about the security of vanilla DES as alluded in the papers conclusion.
