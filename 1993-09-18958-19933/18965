Path: msuinfo!uwm.edu!cs.utexas.edu!wupost!crcnis1.unl.edu!moe.ksu.ksu.edu!phys.ksu.edu!rjq
From: rjq@phys.ksu.edu (Rob Quinn)
Newsgroups: comp.arch,sci.crypt
Subject: Re: Putting Copy Protection in the CPU
Date: 31 Aug 1993 14:47:37 GMT
Organization: Kansas State University
Lines: 69
Message-ID: <25voa9$l0o@newserv.ksu.ksu.edu>
References: <1993Aug31.114242.933@cs.su.oz.au>
NNTP-Posting-Host: bohr.phys.ksu.edu
Xref: msuinfo comp.arch:43489 sci.crypt:18965

In <1993Aug31.114242.933@cs.su.oz.au> mrj@moria.cs.su.oz.au (Mark James) writes:
>One way to robustly implement protection against illegal copying
>of software would be to put it into the CPU.

 You're thinking PC here. On most multiuser, multitasking OS's, users don't
have access to the bare CPU and hardware devices.

>Software would be purchased over the phone, or at a store,
>to run on a particular (individual) CPU chip (identified by an
>id number).

 This is already done. In SunOS4.1.2 (and other OS's I imagine) there's a
gethostid() system call. Here's part of my man page:
DESCRIPTION
     gethostid() returns the 32-bit identifier  for  the  current
     host,  which  should  be  unique across all hosts.  On a Sun
     workstation, this number is taken from the  CPU  board's  ID
     PROM.
 This is used by the hostid command for instance:
%hostid
5541c7be

 I have one, maybe two large packages that refuse to run if they aren't on the
correct host. So, how do these packages know that when they call gethostid()
they are calling the real function, and not something I've put in myself?
Remember, they don't have access to the real CPU or hardware. I can stick in
anything I want between the program and the CPU (well maybe not _ME_ but there
are others with the skill). The same goes for packages that query the date to
see if a license has expired.

> It would be possible to purchase a second copy for
>a notebook-type CPU for a small additional charge.  Of course this
>would prevent the second-hand sale of software separate from its CPU,
>but software prices should come down with a reduction in piracy.

 Not. Like someone else said, stuff like this sucks. I called in to TempleGraph
to get a new key to run their license server on our new machine. They said it
would cost $$. I said no way. Do you think they have a happy customer?

>The CPU would have to have a unit to decrypt an incoming instruction
>stream.  Instructions would be stored in the on-chip instruction cache
>in decrypted form to significantly cut down on the amount of decryption.
>No plain-text version of the code is ever stored externally.

 Seems like your method is only good if the hardware and software companies
are working together, or are the same, such as with nintendos and such.

>There would also be an instruction to turn encryption off and on so that
>the CPU would run plain-text software (e.g. public domain software).

 Real computers can run more than one program at once.

>* If secret algorithms/keys were put on the chip as gates or microcode,
>  how easy would it be for it to be reverse-engineered by inspecting
>  a die?  Can a extra non-conducting layer be added to the wafer to
>  mask this part of the chip?

 See much discussion on the Clipper Chip.

>If feasible, such a chip would be very popular with software
>companies.

 But not consumers (the people with the money).

--
| Open the pod bay doors please Hal.                                       |
| Open the pod bay doors please Hal.                             Rob Quinn |
| Hal, can you hear me?                                   rjq@phys.ksu.edu |
| Open the pod bay doors Hal!                        QuinnBob@KSUVM.BITNET |
