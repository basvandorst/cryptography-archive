Xref: msuinfo sci.crypt:7715 comp.compression:2618
Path: msuinfo!caen!zaphod.mps.ohio-state.edu!sample.eng.ohio-state.edu!purdue!mentor.cc.purdue.edu!pop.stat.purdue.edu!hrubin
From: hrubin@pop.stat.purdue.edu (Herman Rubin)
Newsgroups: sci.crypt,comp.compression
Subject: Re: Source for _real_ random numbers
Summary: Improving biased physical random numbers
Message-ID: <40812@mentor.cc.purdue.edu>
Date: 18 Mar 92 16:06:51 GMT
References: <unruh.700878650@physics.ubc.ca> <1992Mar18.022728.25075@athena.mit.edu> <bruce.700895770@harry>
Sender: news@mentor.cc.purdue.edu
Followup-To: sci.crypt
Distribution: usa
Organization: Purdue University Statistics Department
Lines: 32

In article <bruce.700895770@harry> bruce@harry.ugcs.caltech.edu (Bruce J Bell) writes:
>jfc@athena.mit.edu (John F Carr) writes:

			..................

>One simple and effective(?) way to remove non-randomness from
>physically-generated random numbers is to xor several near-
>or semi-random bits together for 1 output bit.  This will reduce
>deviations from randomness by raising them to a power of the
>number of bits xor'ed.  eg:

>suppose the probability of a 0 for each bit is 0.5 + e
>xor of 2 bits: P(0) = (.5+e)^2 + (.5-e)^2 = .5 + 2*e^2
>xor of 4 bits: P(0) = .5 + 8*e^4
...

>Can anybody see any problems with this?  As long as |e| < 0.5, the xor
>of n bits will converge to a .5/.5 probability exponentially with n.
>What about higher-order statistics?

This procedure is more than 50 years old, but it requires that the bits
are independent.  It is quite useful if the e's are not the same, nor do
they need to be constant.  If the e's can be assumed equal, very much
better procedures can be obtained.

I would be very worried about both the independence and the constancy of
the probabilities for successive bits from any physical device.
-- 
Herman Rubin, Dept. of Statistics, Purdue Univ., West Lafayette IN47907-1399
Phone: (317)494-6054
hrubin@pop.stat.purdue.edu (Internet, bitnet)  
{purdue,pur-ee}!pop.stat!hrubin(UUCP)
