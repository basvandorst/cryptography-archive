Path: msuinfo!caen!sdd.hp.com!cs.utexas.edu!sun-barr!apple!netcomsv!mork!pdh
From: pdh@netcom.com (Phil Howard KA9WGN / I am the NRA)
Newsgroups: sci.crypt
Subject: Re: Source for _real_ random numbers
Message-ID: <lg9ha7fpdh@netcom.com>
Date: 17 Mar 92 22:01:32 GMT
References: <1992Mar16.153445.5771@cs.dal.ca> <92Mar16.131831edt.203@neuron.ai.toronto.edu> <CONSP04.92Mar16170227@bingsuns.bingsuns.cc.binghamton.edu> <28587@crdgw1.crd.ge.com>
Distribution: usa
Organization: Netcom - Online Communication Services  (408 241-9760 guest)
Lines: 26

davidsen@yeti.crd.GE.COM (william E Davidsen) writes:

>|  This method is almost certain to be unhelpful.  Textfiles are
>|  exceedingly non-random; they have all kinds of easy statistics that
>|  cryptographers grab hold of.  Cryptanalysts do this for a living!

>Compressed text files are no longer filled with those nice redundancies.
>As a matter of fact compression removes the redundancy. Computer
>scientists do this for a living (and programmers do it for fun).

There is still SOME redundancy left, depending on compression algorithm.
However MOST of the redundancy is now gone (compression depends on it).

The only way to eliminate redundancy is to catalog every possible message
and identify each by number.  Not practical of course.

Still, this is a very good reason you should always compress your data
before encrypting it.

In addition, compressed data means fewer CPU cycles needed in the
encryption process.
-- 
/***********************************************************************\
| Phil Howard  ---  KA9WGN  ---  pdh@netcom.com   |   "The problem with |
| depending on government is that you cannot depend on it" - Tony Brown |
\***********************************************************************/
