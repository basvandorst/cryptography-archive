Newsgroups: comp.ai,comp.ai.nat-lang,comp.compression,sci.crypt
Path: msuinfo!agate!howland.reston.ans.net!europa.eng.gtefsd.com!library.ucla.edu!whirlwind!ucla-cs!oahu.cs.ucla.edu!jperry
From: jperry@oahu.cs.ucla.edu (John Perry)
Subject: Re: American language standardized dicti
Nntp-Posting-Host: oahu.cs.ucla.edu
References: several
Organization: UCLA, Computer Science Department
Message-ID: <1993Dec20.183340.8769@cs.ucla.edu>
Date: Mon, 20 Dec 93 18:33:40 GMT
Lines: 24
Xref: msuinfo comp.ai:20117 comp.ai.nat-lang:1003 comp.compression:9941 sci.crypt:22145

davesparks@delphi.com (Dave Sparks) writes:
>  
>What would seem really useful would be a long dictionary of English words,
>sorted according to frequency of usage.  That way, you could take a
>dictionary containing 128K words, for example, and easily create a smaller
>dictionary containing the "n" most commonly used words, and "n" could be a
>convenient power of two.
>
>Does such an item exist, or has it been considered?
>

  Try these:

  Henry Kucera and W. Nelson Francis.  Computational Analysis of Present-Day
  American English.  Brown University Press, Providence, 1967.

  Anne Zettersten.  A Word-Frequency List Based on American English Press 
  Reportage.  Publications of the Department of English, Vol. 6, University
  of Copenhagen, 1978.

				happy typing :-),
				John


