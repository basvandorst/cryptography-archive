Newsgroups: sci.crypt,alt.security.pgp
Path: msuinfo!caen!spool.mu.edu!yale.edu!ira.uka.de!rz.uni-karlsruhe.de!stepsun.uni-kl.de!uklirb!posthorn!vier!neuhaus
From: neuhaus@vier.informatik.uni-kl.de (Stephan Neuhaus (HiWi Mattern))
Subject: Re: Zimmermann's responses to Sidelnikov's PGP critique
Message-ID: <neuhaus.726929923@vier>
Sender: news@posthorn.informatik.uni-kl.de (News system account)
Nntp-Posting-Host: vier.informatik.uni-kl.de
Cc: pgp-dev@oc.com
Organization: University of Kaiserslautern, Germany
References: <1993Jan12.015235.18648@netcom.com> <!q5rnkk@dixie.com>
Date: Wed, 13 Jan 1993 12:58:43 GMT
Lines: 115
Xref: msuinfo sci.crypt:12835 alt.security.pgp:1109

jgd@dixie.com (John De Armond) writes:

>What I have NOT read is anyone taking his analysis and trying to confirm
>or deny its validity.  The messenger has been attacked but not the
>message.

Begin TeX mode.

First of all, this is very difficult to do.  For example, the original
posting mentioned that the linear correlation of PGP's random numbers
ranged from $0.001$ to $0.1$ (or something).  It is not clear {\sl which}
source of random numbers he means.  Does he mean the random numbers
used for public key generation or the pseudo random numbers used for
session key generation.

Nevertheless, I have been conductiong a library search lately.
Unfortunately (or fortunately?) the only thing that ended up in my
hands was Knuth II.  He has (approximately) the following to say about
the serial correlation of uniformly distributed integers:

First, for those who don't know what it is, serial correlation
measures, roughly, how well adjacent values in a stream of uniformly
distributed random numbers lie on a straight line if plotted in 2d.
In other words, how well a best-fit line will approximate the set of
$(x,y)$ points that you get if you take $x$ and $y$ to be adjacent
values from the random number stream.

More precisely, let $\{ Y_k \}$ be a sequence of uniformly distributed
random integers, and let $U_k = Y_{2k}$ and $V_k = Y_{2k+1}$ be
subsequences consisting of every second value, for $1 \le k \le n$.
Compute the correlation coefficient $C$ by (heavy \TeX\ follows):

$$
C = { \sum (U_k V_k) - \bigl(\sum U_k\bigr) \bigl(\sum V_k\bigr)
\over
\sqrt{\Bigl(n \sum (U_k^2) - \bigl(\sum U_k\bigr)^2 \Bigr)
      \Bigl(n \sum (V_k^2) - \bigl(\sum V_k\bigr)^2 \Bigr)}},
$$

\noindent where all summation indices range from $1$ to~$n$.

This coefficient will always lie between $-1$~and~$1$.  A value of $0$
means that adjacent values of the sequence are not correlated at all
(i.e., cannot be described by a straight line very well most of the
time), and a value of $\pm1$ means that the values are so strongly
dependent on one another that there actually exist $a$ and $b$ with

$$
Y_{2k+1} = aY{2k} + b.
$$

\noindent I hope it is clear to anybody why one would want $|C|$ to be
small compared to $1$.

Knuth then asserts that even with truly random numbers, we would not
have $C$ exactly zero most of the time.  This is clear because the
numbers are, well, {\sl random}, so even if they are not correlated in
general, for any finite $n$ we will detect a correlation that in fact
isn't there.

Knuth then goes on to say that it is ``conjectured at this time'' that
$C$ has mean and standard deviation of

$$
\mu_n = - {1 \over n - 1}, \quad
\sigma_n = {1 \over n - 1} \sqrt{ n (n + 3) \over n + 1}, \qquad
\hbox{for $n > 2$},
$$

\noindent and that $C$ will lie between $\mu_n - 2\sigma_n$ and $\mu_n
+2\sigma_n$ about 95\% of the time.

Now what does this mean for Sidelnikov's claims?  This can mean a
number of things:

\item{1.} That he used too small an $n$.  For example, if $n = 10^6$,
then $\mu_n \approx -10^{-6}$, and $\sigma_n \approx 10^{-3}$, fixing
the acceptable interval at approximately $[-0.002, 0.002]$. If he
created $2^{32}$ random numbers, the cruical value of $\sigma_n$ would
be approximately $1/2^{15}$ or $3.05\cdot 10^{-5}$.  This means that
we shouldn't set our hopes too high anyway.  (I agree that $0.1$ would
be way too high, though.)

\item{2.} Maybe he meant that $10^{-3}$ was too large a serial
correlation anyway.  We don't know that, because it's not in his text.

I have written a small test procedure to compute the serial
correlation coefficient and am currently testing PGP's random numbers.
(There remains the small matter of winning the Volleyball tournament
today, but aside from that, \dots) It's just that it's very difficult
to answer his claims because in the form that we received them, they
are very imprecise.  The posting just said that the serial correlation
of the random numbers was such and such.  What random numbers?  Did he
use the least 32 bits of a 128-bit random number or did he concatenate
individual bits?  What routines were called?  What $n$ was used?  You
get the picture.

I agree that science should not degrade to name-calling, but science
should also not consist of making too vague claims, English skills
aside.  It has always been SOP to support your claims with hard facts,
such as a description of the test procedure you carried out etc., and
for good reason: So that others could duplicate your results.

Mr Sidelnikov, if you read this, obviously you {\sl have\/} conducted
extensive tests, so please give us a hint where to look.  (I'm {\sl
not\/} flaming, please understand!)

I'll post my results as soon as they are available.

Have fun.

-- 
Stephan <neuhaus@informatik.uni-kl.de>
sig closed for inventory.  Please leave your pickaxe outside.
PGP 2.1 public key available on request.  Note the expiration date.
