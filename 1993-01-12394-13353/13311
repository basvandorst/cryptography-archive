Newsgroups: sci.crypt,alt.security.pgp
Path: msuinfo!caen!zaphod.mps.ohio-state.edu!howland.reston.ans.net!spool.mu.edu!yale.edu!ira.uka.de!rz.uni-karlsruhe.de!stepsun.uni-kl.de!uklirb!posthorn!vier!neuhaus
From: neuhaus@vier.informatik.uni-kl.de (Stephan Neuhaus (HiWi Mattern))
Subject: Re: The Sidelnikov Saga... Now he's wrong again.
Message-ID: <neuhaus.728309892@vier>
Sender: news@posthorn.informatik.uni-kl.de (News system account)
Nntp-Posting-Host: vier.informatik.uni-kl.de
Reply-To: neuhaus@informatik.uni-kl.de
Cc: neuhaus@informatik.uni-kl.de
Organization: University of Kaiserslautern, Germany
References: <D0F1XB1w165w@tornado.welly.gen.nz>
Date: Fri, 29 Jan 1993 12:18:12 GMT
Lines: 146
Xref: msuinfo sci.crypt:13311 alt.security.pgp:1320

sai@tornado.welly.gen.nz (Simon McAuliffe) writes:

>The correlation formula posted recently makes good sense, but looking at
>the formula for the mean, you can't help feeling something is wrong.

>                    1
>           mu  =  -----,  n >= 2
>                  n - 1

I was the one who posted the formula, and I can only repeat what my
source, Knuth II, had to say:

	A ``good' value of C will be between mu + 2sigma and mu -
	2sigma, where

                                          ----------
              -1                  1      / n (n - 3)
	mu = -----,	sigma = -----   /  ---------,	n > 2
             n - 1              n - 1  v     n + 1

	We expect to lie C within these limits 95% of the time.

	The formulas [for mu and sigma] *are only conjectured at this
	time*, because the distribution of C isn't known whan the Us
	are uniformly distributed. [...] Empirical evidence suggests
	that we may safely use the formulas for the mean and standard
	deviation that have been derivedfrom the assumption of the
	normal distribution, without much error.  [Emphasis added.]

This quote is from

@book(knuth-ii
    author=dek,
    title={Seminumerical Algorithms},
    publisher={Addison-Wesley},
    year=1981,
    volume={2},
    series={The Art of Computer Programming},
    edition={Second},
)

page 71.

Another book,

@book(recipes,
    author={William H. Press and Brian P. Flannery and Saul A. Teukolsky
        and William T. Vetterling},
    title={Numerical Recipes in C},
    publisher={Cambridge University Press},
    year=1988,
    address={Press Syndicate of the University of
        Cambridge, The Pitt Building, Trumpington Street, Cambridge
        CB2 1RP, Great Britain; 32 East 57th Street, New York, NY
        10022, USA; 10 Stamford Road, Oakleigh, Melbourne 3166,
        Australia},
    edition={Second},
)

says the following about serial correlation (on page 503f):

	About the only general statement that can be made is this: If
	the null hypothesis is that x and y are uncorrelated, and if
	the distributions for x and y each have enough convergent
	moments (``tails'' die off sufficiently rapidly), and if N
	[the number of samples -- neuhaus] is large (typically > 20),
	then r [what we call C -- neuhaus] is distributed
	approximately normally with a mean of zero and a standard
	deviation of 1/sqrt(N).  In that case, the (double-sided)
	significance of the correlation, that is, the probability that
	|r| should be larger than its observed value in the null
	hypothesis, is

                     / |r| sqrt(N) \
		erfc | ----------- |
                     \   sqrt(2)   /

	where erfc() is the complementary error function [...].

(Please, David, don't flame me for using BiBTeX format for the
references, okay?  I'm already having a hard enough time writing the
formulas in ASCII. :-)

As you see, *both* sources talked about *approximate* normal
distributions, and the second source emphasizes that N must be large.

>Okay, back to the formula for the mean.  Substituting n = 2 into the
>equation yields mu = 1.

The equations are valid only for n > 2; in the case n = 2, the square
root for the standard deviation gets negative.  That was an error in
my posting.  Sorry for that.  (But you would have realized this if you
had also tried to calculate sigma.)

>This problem is also true for n = 3, n = 4 and upwards, it just becomes
>less ridiculous for larger n.

Question (curiosity): How ridiculous is this for 3 and 4 points? (In
other words, if n = 3 or 4, and if the random points are really
uniformly distributed, what is the expected value of C, if calculated
by first principles of probability theory?)

>So I think we can assume that the given equation is not really what it
>was intended to be.  I don't know what Knuth's book really says because
>I don't have it, but perhaps there was something lost in the posting of
>it?

As far as I can tell, the above is an *exact* transcription of what's
in Knuth.

>The test statistic is,
>                         _
>                         x - mu
>               t  =  -------------
>                      s / sqrt(n)

Which surprises me, since I thought that the t-test could only be
applied to two *sampled* distributions.  But then, I'm no
statistician either, so could you please post a reference where this
formula can be found?  (I assume that you are using the t-test for
paired samples, and your equation would imply that you set

	var(x2) - 2cov (x1, x2) = 0

where x2 is the "real" distribution and x1 the sampled one.
Incidentally, this is formula (13.4.6) in the Recipes book cited
above.)

>There may still be correlation between other bits.  I believe somebody
>is working on this area as we speak however.  There may also be other
>weaknesses in IDEA which result in weak random numbers. I imagine some
>people are working in this area too.

Yup.  I am these people :-).  As far as I know, you and I are the only
ones who actually do any tests (and publish their results).  So far, I
have found nothing.  I'm still testing, but I'm also graduating at the
same time, so don't expect me to post anything soon.  I *will* post
immediately if I should find something nonrandom.  However, evidence
suggests that I might not have the resources to find nonrandomness.

Have fun.

-- 
Stephan <neuhaus@informatik.uni-kl.de>
sig closed for inventory.  Please leave your pickaxe outside.
PGP 2.1 public key available on request.  Note the expiration date.
