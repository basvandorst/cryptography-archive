Newsgroups: sci.crypt,alt.privacy
Path: msuinfo!agate!howland.reston.ans.net!darwin.sura.net!haven.umd.edu!uunet!leviticus!sgs
From: sgs@grebyn.com (Stephen G. Smith)
Subject: So What do We Really Want?
Message-ID: <C906sF.6qx@grebyn.com>
Followup-To: sci.crypt
Summary: Don't like Clipper?  Come up with something better!
Organization: Agincourt Computing
Date: Tue, 22 Jun 1993 03:24:14 GMT
Lines: 132
Xref: msuinfo sci.crypt:17433 alt.privacy:7511

Okay, so nobody likes Clipper.  Even its proponents are saying things
like "Well, it's better than nothing".  What should we use instead?

Instead of fussing about how bad Clipper is, why don't we try to come up
with a functional spec for a better system?  Who knows, maybe some
enlightened (read: greedy :-) manufacturer will actually build the thing!
The following contains some of my thoughts on the subject, as a way of
getting things started.  What kind of a system would *YOU* want to use?

----BEGIN POLITICAL COMMENT

This must be done *NOW*.  The longer we wait, the more likely we are to
be swamped by bad Government-mandated security systems. If we have
something in place by the time the governments involved figure out
what's going on, then we win.  Governments are like icebergs -- hard to
get moving, but almost impossible to stop.  (Also, it's the hidden part
that kills you ....)  If the governments figure out what is going on
before we get underway, we're screwed.

Note that the US Government has a warehouse full of Clipper chips and
Bell Atlantic Clipperphones ready to dump onto the market.  A
commercial system would probably cost about 1/3 of what the
Clipperphone would cost, but if the US Government decided to take a
loss in order to build market share, things could get grim.

----END POLITICAL COMMENT
                                                                     
The basic specifications I see as being relatively noncontroversial:

1.  No back doors.  Of any kind.  Period.  This is the concensus from
    the Clipper debate, held by everybody except Dorothy Demming.

2.  All algorithms used must be available for public scrutiny and
    analysis.

3.  Immune from any "brute force" attack, now and for the next (say) 20
    years.  This lets out, for example, single DES.

4.  International.  None of this "USA and Canada only" nonsense. Note
    that this will probably require the detailed design and manufacture
    of the system to be outside the US.

5.  Under personal control.  This means that I am responsible for my own
    key security.  Also, I can change my keys at any time.

6.  Immune to "man in the middle" attacks.  Near as I can tell, this
    will mean that we'll have to introduce a "Public Key Certification"
    agency of some kind.

7.  Reasonably easy to use.  We want these things to be used by
    *everybody*, not just us computer geeks (:-).  Key generation and
    storage is a problem here, as it will probably need a PC or some
    such.  Nintendo cartrige? (1/2 :-)

What would it look like?  I envision a little box that looks just like a
modem, with an "encrypt" button and some extra LEDs showing things like
incoming encrypted call, encrypted communication established, encrypted
communication refused, verification in progress, etc.  I would also add
a "scram" button that would immediately erase any private data (session
keys or private keys) stored in the device.  The RS-232 port would be
used both for private key loading (if we don't generate public-private
rey pairs internally) and for general (non voice) data transfer.  No
reason why we can't use it as a normal modem (encrypted or clear) ....

What's inside?  Now we get to the fun stuff!  A modem, obviously.  The
list of functions in the Capstone chip (Block cipher unit, random number
generator, generalized exponentiation unit, signature generator/checker,
secure hashcode generator, etc) sounds about right, but we need to put
some names to them.  IDEA for the block cipher, for example?  Also, I
would add a clock running GMT and timestamp everything in sight.

Most important, from a security standpoint, is the session establishment
protocol.  My thoughts run to something like this (suggestions welcome
and probably needed :-).

1.  The first thing I do when I get my shiny new sci.crypt Encryptation
    Unit (SCEU) (Priority - come up with a catchy name :-) is to
    generate a public key-private key pair.  I stash my private key
    someplace that is as safe as possible.

2.  I generate a message to one or more Key Certification Authorities
    (KCA) giving my public key and "valid from - to" date information. I
    sign it and send it off.

3.  The KCA sends me a message, properly signed, giving my public keys
    and validity information. I verify the signature and load it (or
    them, if I'm using multiple KCAs) into the SCEU.  Now I can load my
    private keys into the SCEU, and I'm ready for private calls.

When I am talking to you, and we decide to "go private", the sequence of
events looks like this:

1.  Our SCEU's query each other for our respective public keys.  We each
    verify the KCA's signatures.  If the signatures don't verify, then
    we can't "go private".

2.  If all the signatures verify properly, then we negotiate a session
    key.  This can be as simple as having one side generate a random
    number, checking to make sure it is a "good" key, encrypting it with
    the other side's public key, signing it, and sending it out.

3.  Decrypt the session key, verify the signatures and timecodes, load
    it into the block cipher unit and we're on the air!

The big problem I see here is the KCAs.  They would have to keep their
own private keys as secure as possible -- bank vaults and so on.  Their
public keys must be distributed by as many channels as possible to
prevent spoofing.  I assume that they would charge a small fee for
"signing" a public key.  Note that they don't have to store it --
everybody gets my public key directly from me.  The KCA's signature is
your guarantee that it is really mine, and not a "spoofer".  If I use a
KCA in Finland and you use one in Switzerland, then spoofing the system
becomes a major diplomatic effort.

Running a secure KCA will be a rather difficult and expensive operation.
In addition, the "signing fee" must be as small as possible, to
encourage people to change their keys as often as they feel is
necessary.  If millions of people use SCEUs, a KCA would be a gold mine
(1 million users * 1 key change/month * US$5.00/key change = US$5
millon/month cashflow.  Not chickenfeed.)  Unfortunately, to start out
with, a KCA might have only a few hundred customers.  They would lose
money with any reasonable charge.

Perhaps have a mode that uses uncertified keys and damn the Man in the
Middle?  (I don't like it.  Then we're no better than Clipper :-)

Okay, there it is.  Suggestions?  Anybody else want one?

-- 
Steve Smith                     Agincourt Computing
sgs@grebyn.com                  (301) 681 7395
"Truth is stranger than fiction because fiction has to make sense."
