Newsgroups: sci.crypt
Path: msuinfo!uwm.edu!cs.utexas.edu!uunet!math.fu-berlin.de!jiri
From: jiri@spider.chemie.fu-berlin.de (Jiri Pittner)
Subject: Re: Re: entropy of compressed vs. well encrypted file
Message-ID: <FWIEB0CW@math.fu-berlin.de>
Keywords: encryption, entropy
Sender: news@math.fu-berlin.de (Math Department)
Organization: Free University of Berlin, Germany
Date: Thu, 17 Jun 1993 11:37:57 GMT
Lines: 68


In sci.crypt ahaley@eoe.co.uk (Andrew Haley) writes:

>Jiri Pittner (jiri@spider.chemie.fu-berlin.de) wrote:
>: In sci.crypt ahaley@eoe.co.uk (Andrew Haley) writes:

>: >>David Neal (dneal@NeoSoft.com) wrote:
>: >>: In article <kurtwwC8LnJo.2CD@netcom.com> kurtww@netcom.com (Kurt Wiedenhoeft) writes:

>: >>: 1) The NIST announcement specifically states that Clipper
>: >>:    looks for superencryption of the Law Enforcement Block.

>: >This really is silly.  Any well compressed data has entropy almost
>: >equivalent to random data- ie it's almost impossible to distinguish it
>:                                ----------------------------------------
>: >from encrypted data.  Is the Clipper spec going to say that it will
>:  -------------------
>: >fail for entropies above x?  So if you attempt to send a JPEG file it
>: >will fail?

>: [something deleted]

>: I cannot agree with that statement. The best public domain file compression
>: program (according to my tests) is 'lha' and for compressed text with
>: size of compressed data 600K I have measured entropy 7.998993/byte - 
>: just 8-1e-3. Encrypted file of approx the same length, (my encryption program
>: which is also posted here has been used) gives entropy 7.9997, which is
>: 8-3e-4. It should be looked more on the difference from 8. On short files
>: the differences are not so obvious. 

>But Clipper never gets to see 600K blocks.  As far as I know, Clipper
>encrypts short data blocks (8 bytes?), one at a time.  Clipper would
>need to do a lot of computation and contain a lot of memory in order
>to discover whether the data was compressed data, noisy audio data, or
>whatever.  And it would need an unrealistic amount of data to do the
>checking.  Also, it's easy for any encryption program to generate
>output which looks decidedly nonrandom, at the cost of some expansion
>of the ciphertext.  For example each ciphertext byte could be encoded
>as an English word, and you could then compress the ciphertext; how
>would you then be able to tell?

I think that simple substitution of one byte with one english word
would give file with quite lower entropy than average english text has.
But anyway, I agree that there are many ways of conversion of ciphertext
to something what does not look like ciphertext. One idea I have seen somewhere
in this group was to use least significant bit of digitized image or sound,
for example. I think that such chip as Clipper does not have a possibility
to check its input and that its authors really did not try to do that, because
there are so many ways how to confuse such testing algorithms.

>: Anyway, much better test for distinguishment of compressed and crypted file
>: is chi-square test of occurencies of bytes (0-255), or also byte pairs.
>: I HAVE NEVER SEEN ANY OUTPUT OF COMPRESSION PROGRAMS WHICH WOULD PASS
>: CHI-SQUARE TEST!

>: THE OUTPUT OF MY (AND ANY STRONG) ENCRYPTION  PROGRAM PASSES THIS TEST.

>That really isn't so.  A strong encryption program can easily be
>written to _fail_ the pairs chi-square test.

Well, I have to formulate my idea more precisely: 
   I think during the strong encryption there must be some intermediate
   ciphertext, which passes statistical tests. Otherwise the cryptanalyst
   could profit from its  deviations from randomness. Of course, such 
   'intermediate ciphertext' can be than processed in many ways, to make
   the final ciphertext with wished properties.

>Andrew.
