Path: msuinfo!netnews.upenn.edu!news.amherst.edu!news.mtholyoke.edu!uhog.mit.edu!MathWorks.Com!europa.eng.gtefsd.com!howland.reston.ans.net!math.ohio-state.edu!jussieu.fr!univ-lyon1.fr!swidir.switch.ch!scsing.switch.ch!xlink.net!zib-berlin.de!news.dfn.de!Germany.EU.net!EU.net!uunet!newsflash.concordia.ca!sifon!mcrcim.mcgill.edu!collatz.mcrcim.mcgill.edu!mouse
From: mouse@collatz.mcrcim.mcgill.edu (der Mouse)
Newsgroups: sci.crypt
Subject: Re: Odds of different messages having same MD5 signature?
Date: 15 Jun 1994 21:39:20 GMT
Organization: McGill Research Centre for Intelligent Machines
Lines: 70
Message-ID: <Mouse.Wed_Jun_15_17_06_10_1994@collatz.mcrcim.mcgill.edu>
References: <CrEnsH.5w6@world.std.com> <2tgq66$p1n@pdq.coe.montana.edu> <grinch-130694225156@grinch.tor.
NNTP-Posting-Host: thunder.mcrcim.mcgill.edu

>>> Given 2 equal length files, what are the odds that 2 images will
>>> generate the same MD5 signature?
>> The odds are 2**(-128) that any two specific files will generate the
>> same MD5 hash.
> Does this apply regardless of file size?

Yes, assuming of course that the files are at least 128 bits long.  If
they're shorter, the probability may change; it might be zero, it might
be 2^-N, where N is the file size in bits, it might be 2^-128 - I'd
have to think about it a good deal to be sure.  (Assuming, of course,
that the files are in fact different. :-)

>> Thanks to the birthday 'paradox' the odds that *any* two files will
>> have the same hash is much, much, higher.

(This needs a little clarification.  The full statement is that the
probability that any two files out of some given collection have the
same hash is much higher than one might "normally" expect.  There's no
question that there exist two files with the same hash; indeed, the
pigeonhole principle guarantees that there exists some hash that an
infinity of different files hash to...and all the (public) information
available indicates that all 2^128 hash values have this property.)

> What exactly is the birthday paradox?

The usual formulation is "how many (random) people do you need in a set
before the chance of two people having the same birthday reaches 50%?".
The actual number is something like 25, far less than the 182 or so
that seems to be the intuitive snap reaction.  The probability that K
objects, each with a property ranging uniformly over [1..N], has at
least two objects with a common property value, is perhaps most easily
computed by evaluating the converse probability, that no two objects
have a common value.  This is simply (N-1)/N for two objects,
[(N-1)/N][(N-2)/N] for three, and more generally, for K,

	K - 1         /  K-1
	prod  (N-i)  /  N
	i = 1       /

Actually calculating this precisely for numbers as large as we're
dealing with here is a major waste of CPU time.  Instead, one usually
makes rough estimates: for example, how many different random files
must one examine before the expected probability of finding two with
the same hash reaches 50%?  I don't think anyone knows the exact
answer, but we can estimate it as follows: if we've accumulated K
files, then we have a K/N chance of a repeat on the next file.  If we
are overconservative and say that each of the K files already had a K/N
chance of a repeat, we get a total (K^2)/N chance of a repeat (a gross
overestimate; see below).  Setting this to 1 gives K=sqrt(N); setting
it to 1/2 gives K=sqrt(N/2), which for our purposes is not
significantly different.  This is little more than a rough answer, of
course; but it is an indication that the work required to find _any_
collision is at least on the rough order of the square root of the size
of the search space.  (The (K^2)/N should be something more like
1-(((N-K)^K)/N), but all we want is an upper bound.  This is an
outrageously loose upper bound, but it gives us enough for our
purposes.)

Thus we can, for example, be sure that if we examine only 2^63 files,
we have no more than a 50% chance of finding an MD5 collision, since we
(grossly) overestimated probabilities, but never underestimated.

All of this assumes MD5 is as good as everyone hopes it is: that it
maps any given file to a statistically random one of the 2^128 possible
hashes.  Any regularity discovered in MD5 hashes would be a point of
attack for narrowing this search down.

					der Mouse

			    mouse@collatz.mcrcim.mcgill.edu
