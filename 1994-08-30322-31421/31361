Path: msuinfo!news.mtu.edu!sol.ctr.columbia.edu!newsxfer.itd.umich.edu!gatech!news-feed-1.peachnet.edu!umn.edu!newsdist.tc.umn.edu!msus1.msus.edu!solar!mmorgan
Newsgroups: sci.crypt
Subject: entropy
Message-ID: <1994Aug29.233527.1635@msus1.msus.edu>
From: mmorgan@ee.stcloud.msus.edu (Michael S. Morgan)
Date: 29 Aug 94 23:35:26 -0500
Reply-To: mmorgan@solar.ee.stcloud.msus.edu
Sender: mmorgan@solar (Michael S. Morgan)
Distribution: world
Organization: St. Cloud State University, EE Department
Nntp-Posting-Host: solar.ee.stcloud.msus.edu
Lines: 30

I have written a program that calculates the entropy
of a file based on character probabilities.  I wrote
it as a crypto-tool, but have not made much use of it.

Anyway, other than observbed character frequencies,
would a 64-bit wide frequency count yeild a better
tool?  I suppose the files would have to be huge before
such a program would be useful.

Also, as far as random number generators go, if the 
entropy is low, then the number generator is probably
not as good as it could be, right?  And if the entropy
is high, you do not know anything except that your
random number generator is not obviously bad, right?

Now, rand() does not produce random numbers, "especially
on the lower bits", which seems to suggest that not
only should one look at the numbers being generated, but
one should also look at parts of the numbers being generated,
right?

-- 
-------------------------------------------------------------------+
Michael S. Morgan      | xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx       |
    User ID:  A25C69C5 | xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx |
Fingerprint:  1560FD25 |                                           |
              431D1014 | Why are they trying to ban milita rifles? |
              3EEAE3C3 |                                           |
              F9CDB465 | xxxx xxxx lives.                          |
-------------------------------------------------------------------+
