Path: msuinfo!agate!howland.reston.ans.net!gatech!psuvax1!castor.cse.psu.edu!beaver
From: beaver@castor.cse.psu.edu (Don Beaver)
Newsgroups: comp.theory,sci.crypt
Subject: Re: UTM via boolean circuit & secure multiparty computation
Date: 29 Aug 1994 14:54:03 GMT
Organization: Penn State Computer Science
Lines: 131
Distribution: inet
Message-ID: <33ssqb$p60@psuvax1.cse.psu.edu>
References: <szaboCv6MDK.H8D@netcom.com>
NNTP-Posting-Host: castor.cse.psu.edu
Xref: msuinfo comp.theory:10242 sci.crypt:31317

szabo@netcom.com (Nick Szabo) writes:
>Secure multiparty computations are protocols where every 
>participant learns the value of the computed function, but no
>one learns anything about the inputs of any of the other members
>(except what they can infer from their own input and the output
>value).  Alice and Bob, for example, create an arbitrary
>boolean circuit.  The circuit accepts input from Alice and
>Bob and computes an output.  Alice can enter input without
>Bob being able to learn it, and vice versa; Alice and
>Bob can each calculate the output and know that the other
>did not tamper with it.  (Alice and Bob being honest about their
>inputs, if necessary, is outside the scope of the protocol).

There is a rich variety of results, depending on several parameters,
including:

. two-party vs. n-party
. perfect (info-theoretic) security vs. "computational" security
. honest-but-curious vs. malicious attacks
. fault-tolerance (<n/3, <n/2, >=n/2)

(Please ask if these keywords aren't descriptive enough.)


>* Can the function be a universal Turing machine, for
>example a boolean circuit within a simple loop containing a 
>small amount of state?  Can state be transferred from one 
>iteration to the next without leaking it to Alice or
>Bob?

2-party, computational, honest-but-curious:  YES.

2-party, perfect, honest-but-curious:        NO.
  Essentially all you can do is to trade parts of your input
  (e.g. exclusive-or, sum mod m, etc.)  You cannot do AND, OR.

2-party, computational, malicious:           NO.
  Either party can stop the other from learning the result.  The best
  you can do is to slow down the rate at which the result is revealed,
  so that (roughly speaking) nobody gets more than a one bit advantage.


For n-party protocols, let  t  be the max number of faults.

n-party, computational, malicious, t<n/2:    YES.

n-party, computational, malicious, t>=n/2:   NO.
  The answer becomes yes if you aren't worried about fairness.  As in
  the 2-party case, bad players can stop the protocol before the
  result is completely known.

n-party, computational, honest-but-curious, t>=n/2:  YES.

n-party, perfect, malicious, t<n/2:          YES.

n-party, perfect, honest-but-curious, t>=n/2: NO.
  You can do exclusive-or, sums mod m (any m), and some slightly
  more complicated functions.  You can't do AND, OR.

I clearly haven't listed all the cases, but other results are implicit
(for example, if you can't protect against honest-but-curious faults,
then you certainly can't protect against malicious faults).


>* is there any good analysis on information leakage for
>multiparty secure (a) boolean circuits, and (b) if possible 
>boolean circuits run repeatedly as UTMs? What kinds of
>functions are most leak-proof?

This depends heavily on the fault-tolerance and number of parties.


>* could the function be constructed from some other algebra 
>than boolean, for example a Galois field?

Absolutely.  In fact, many of the theoretical results require a
reasonably-sized field to do things like secret sharing,
and in adapting such fields to accomodate boolean algebra
they tend to underutilize the arithmetic already at hand.
(E.g. they might use arithmetic over GF(256) to construct a
protocol that simulates a boolean circuit that in turn computes
sums bitwise over GF(256)...)


>* in general terms, what is the performance penalty in
>time and space for computing functions this way over
>a network?

Polynomial.  (!)  :-)

For two-party protocols, a couple of rounds suffices, and the 
message size is on the order of the space that a trusted host
would need to do the computation in the first place.

For n-party protocols, the number of rounds is proportional to
the depth of the circuit or the time complexity of the TM
(you can slice off a log factor, or you can do it in constant
rounds based on one-way functions).  For each participant, the
message size is typically on the order of the space needed without
overhead, multiplied by the number of participants.


>* any good references?

(It sounds as though you've read Yao's 1982 FOCS paper.)

Without trying to indicate the history of science on this matter,
try Shamir (secret sharing), Ben-Or/Goldwasser/Wigderson
(perfectly secure, t<n/3 multiparty protocols), and
Goldreich/Micali/Wigderson (computationally secure).
There are other significant papers, but these give you
a taste of some basic ideas.

\bibitem{sha79}
  A.\ Shamir.
  ``How to Share a Secret.''
  {\em Communications of the ACM,} {\bf 22} (1979), 612--613.

\bibitem{bgw88}
  M.\ Ben-Or, S.\ Goldwasser, A.\ Wigderson.
  ``Completeness Theorems for Non-Cryptographic Fault-Tolerant
  Distributed Computation.''
  {\em Proceedings of the $20^{th}$ STOC,} ACM, 1988, 1--10.

\bibitem{gmw87}
  O.\ Goldreich, S.\ Micali, A.\ Wigderson.
  ``How to Play Any Mental Game, or
  A Completeness Theorem for Protocols with Honest Majority.''
  {\em Proceedings of the $19^{th}$ STOC,} ACM, 1987, 218--229.

Don
