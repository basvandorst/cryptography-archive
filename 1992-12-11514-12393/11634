Newsgroups: sci.crypt
Path: msuinfo!caen!zaphod.mps.ohio-state.edu!cis.ohio-state.edu!news.sei.cmu.edu!fs7.ece.cmu.edu!crabapple.srv.cs.cmu.edu!mnr
From: Marc.Ringuette@GS80.SP.CS.CMU.EDU
Subject: Cryptographic copy protection
Message-ID: <ByxHyv.5s9.1@cs.cmu.edu>
Originator: mnr@GS80.SP.CS.CMU.EDU
Sender: news@cs.cmu.edu (Usenet News System)
Nntp-Posting-Host: gs80.sp.cs.cmu.edu
Organization: School of Computer Science, Carnegie Mellon
Date: Tue, 8 Dec 1992 05:17:00 GMT
Lines: 118

[ The quick summary:  I'm trying to figure out if it's possible to 
  use a "cryptographically strong code shuffling" technique to create
  code which is resistant to disassembly.  If so, certain kinds of
  copy protection become practical.  References welcomed.              ]

===

First, some context:  I've been thinking about how the world will look
as bits become cheaper and cheaper to copy and store.  For instance, it
will cost almost nothing to store a musical number on disk and play it
back when desired.  Any static collection of bits will be similarly
copyable.  There is no possibility of copy-protection; if the
information reaches my eyes or ears, then I can record it and give it
to my friends for playback.  This will make it difficult to make money
by selling recordings or books.

Is software copy-protection possible without running the software
solely on trusted hardware?  Is pay-per-use software possible without
hardware "dongles"?  This is the question I'm addressing.  Any
observations or references are welcome.

The point of entry I'm using is the fact that software is interactive.
A single use of a piece of software doesn't reveal all of its intricacies 
(unlike a musical number or a novel).  We can therefore hope to force
a contact with a host machine H during each unique run of the program,
enabling us to insist upon payment.

===

   Given: 
	- a software provider with a host machine H
	- an insecure but highly available network
	- a user with a workstation U, not trusted by the software provider
   Goal:
	- a technique which can take a piece of software S and "securify" it
	  into two parts, Su and Sh, so that developer can send Su to the
	  user, run Sh on host H, and be assured of being paid for each
	  use of the software.  I want a cryptographic guarantee, even
	  against a determined disassembler and specialized hardware.  It
	  is permissible to require a continuous active net connection
	  between the user's machine U and the software provider's host H.

===

I see a spectrum of solutions:

1. This goal can be achieved, in the worst case, by keeping the real
software in Sh, to be run on the trusted host machine H, and having the
user software Su merely establish a net connection to host H, and relay
inputs and outputs.  Then the only possibility of theft is through
reverse-engineering.

2. A weakened form of the same solution is to give the user most of the
software in Su, but keep some critical (and difficult-to-reverse-engineer)
sections in Sh, and have Su ship those computations to the trusted host H.

3. A more general solution would be to include all of the relevant code in
Su, but have it contact host H periodically, using public key cryptography to
verify contact, and require H to agree to continued execution of the program.
In this case, Su must be resistant to disassembly, or the user will just
remove the part of the code that checks for approval by the host.  Since
we seek cryptographic guarantees, this requires a "cryptographically strong
code shuffler" which may or may not be possible under some reasonable set
of assumptions.

4. The ideal solution would be to have a self-contained piece of software S
which need not contact host H at all; each time it is executed, some sort of
"bit-rot" occurs, giving S a limited lifetime.  This is too ambitious; an
opponent can defeat all such schemes by making extra copies of S before
running it for the first time.

===

Scheme 1 is a lowest common denominator.  Scheme 2 is pretty ad-hoc.
Scheme 4 doesn't work.  That leaves Scheme 3, which is the one which 
interests me.

The key to success is "cryptographically strong code shuffling" which
gives a cryptographic guarantee against disassembly, or more precisely,
a guarantee that tampering will be detected.  Such a guarantee doesn't
stop copying in the case where no contact with the host occurs, but
does when the code requires a signed approval from the host before 
continuing.  The code shuffling ensures that the code which contacts
the host cannot be excised from the program without making it non-functional.

I haven't been able to come up with a convincing proof that this goal
is unachievable.  I would expect such a disproof to have the form of a
copying attack which is guaranteed to succeed.  For instance, if the
program takes no inputs, we can prove that a "playback attack" is
always possible; the result of the execution of the same program can
be duplicated merely by writing down its output.  However, if we assume
that the program's inputs are unique on each run, it seems that the
program might "mix" its inputs with its executable code in some way
which makes each run unique, and requires the solution of a unique
cryptographic problem by the host H in order to continue executing.

Here's an incomplete sketch of how to transform a program into such a
non-dissasemblable program.  Take the call graph of the original
program, and expand it into a large lattice of code, with different
branches paths being taken for different values of the input.  The
intention is that each set of inputs leads to at least one new vertex
of the lattice (or, better, a unique path through the lattice with no
unique-vertex requirement).  Then, arrange so that the only way to find
the code to be executed at the next vertex is to solve a cryptographic
problem.  This means that it must not be possible, given the code executed
so far and a number of previous runs of the program, to determine what
code comes next.  In this case, host H must be contacted to solve the
problem.

Can we flesh out this sketch into a scheme by which we can ensure
software pay-per-use on an insecure machine, with a small constant
amount of contact with the host machine (say, 100 small messages)?  
Or can we prove we can't do it?  I haven't managed to do either, yet.

Discussion and references are most welcome.


-- Marc Ringuette (mnr@cs.cmu.edu)
