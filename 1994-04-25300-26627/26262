Newsgroups: sci.crypt
Path: msuinfo!agate!howland.reston.ans.net!europa.eng.gtefsd.com!library.ucla.edu!csulb.edu!csus.edu!netcom.com!mpj
From: mpj@netcom.com (Michael Paul Johnson)
Subject: Re: Decompressing ciphertext
Message-ID: <mpjCooFz7.CCz@netcom.com>
Keywords: compression, Huffman, Arithmetic coding
Organization: NETCOM On-line Communication Services (408 241-9760 guest)
References: <RICK.1.00121813@telescan.com> <16F9FF70CS86.C445585@mizzou1.missouri.edu> <2p8iu6$bp7@ccu2.auckland.ac.nz>
Date: Fri, 22 Apr 1994 20:09:06 GMT
Lines: 40

pgut1@cs.aukuni.ac.nz (Peter Gutmann) writes:
>...
> [some discussion of decompression of ciphertext omitted]
>This has already been done - in Bell, Witten, and Cleary's "Text 
>Compression" the authors build up a model of the Brown Corpus (a very large
>body of English text), and then use it to "decompress" random noise, as an
>experiment in seeing how well the compressors can approximate the original
>source statistics (the result: Not very well).
> 
>A few years ago I came across a program which builds a word-based model of a 
>sample text and then uses a random number generator to create a vaguely 
>realistic but still nonsensical version of the original.  I talked to the 
>author about its use for steganography by replacing the RNG with encrypted 
>data, but it was written in Prolog (quite a lot of Prolog) which I didn't 
>want to mess with.  Certainly it wouldn't be too hard to adapt some 
>"travesty generator" to hide encrypted data, but as with most subliminal 
>channels the bandwidth is rather low.

I did a similar thing a while ago in Pascal.  The compressor used a 
static Huffman code based on English words as symbols.  The compression 
ratios that I achieved came out somewhere between .ARC files and .ZIP 
files.  I also tried decompressing noise, just to see what it looked 
like.  I concluded that I could probably do better in compression (and, 
now that you mention it, in steganography), by adding a little more 
English structural knowledge to the process, like some capitalization, 
spacing, and punctuation rules.  If you went even further and made the 
processor assemble sentences properly (with subject and verb), then the 
resulting nonsense would look enough like the corpus you scanned to 
create the Huffman tree with that it would be even more "convincing."

The implementation is left as an exercise for the reader...

                  ___________________________________________________________
 |\  /| |        |                                                           |
 | \/ |o|        | Michael Paul Johnson  Colorado Catacombs BBS 303-938-9654 |
 |    | | /  _   | mpj@csn.org  ftp:csn.org//mpj/README.MPJ for crypto stuff |
 |    |||/  /_\  | aka mpj@netcom.com mpjohnson@ieee.org mikej@exabyte.com   |
 |    |||\  (    | m.p.johnso@nyx.cs.du.edu CIS 71331,2332 PGP key by finger |
 |    ||| \ \_/  |___________________________________________________________|

