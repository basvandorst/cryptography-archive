From: edward.rice@his.com (Edward Rice)
Path: msuinfo!uwm.edu!math.ohio-state.edu!cs.utexas.edu!uunet!news.his.com!Clone!UUCP
Newsgroups: sci.crypt
Subject: compression & security
Message-ID: <767218856.AA05340@Clone.his.com>
Date: Sun, 24 Apr 1994 14:17:12
X-FTN-To: Dave Sparks
Lines: 23

  DS> From: davesparks@delphi.com (Dave Sparks)

  > I once designed a second order Huffman compression scheme especially for
  > some technical English text.  When I used it to decompress "random"
  > input data, the output looked much like technical English!  Lots of
  > short real words, some long ones, and some very pronounceable nonsense
  > words, with realistic suffixes and prefixes.

(Sorry, I've lost the original message.)

There is an old (late seventies or earlier) hack called The Dissociated Press,
which does much the same thing.  It is a program that reads in text and stores
n-gram (single letter, letter pair, triplet, etc.) occurrence frequencies as it
scans the text.  Then it generates arbno of output units, basing them on the
input frequencies.  It's amazing how well it does... using only 3-grams you end
up with okay-looking words, a little longer and the sentences are readable
(alebit meaningless), and when you start telling it to deal with words and
their adjoining words you start getting some decent text out of it.  If you
feed it enough text and tell it to deal with word-pairs, you can end up with
something that reads like a badly-written press release or administrative
memorandum.


