Newsgroups: sci.crypt
Path: msuinfo!agate!howland.reston.ans.net!cs.utexas.edu!uunet!mnemosyne.cs.du.edu!nyx10!colin
From: colin@nyx10.cs.du.edu (Colin Plumb)
Subject: Re: Searching for primes
Message-ID: <1994Apr6.092808.25303@mnemosyne.cs.du.edu>
X-Disclaimer: Nyx is a public access Unix system run by the University
 	of Denver for the Denver community.  The University has neither
 	control over nor responsibility for the opinions of users.
Sender: usenet@mnemosyne.cs.du.edu (netnews admin account)
Organization: Nyx, Public Access Unix at U. of Denver Math/CS dept.
References: <1994Apr3.224626.13805@mnemosyne.cs.du.edu> <2ns8l0$ikq@linus.mitre.org>
Date: Wed, 6 Apr 94 09:28:08 GMT
Lines: 135

In article <2ns8l0$ikq@linus.mitre.org>,
Robert D. Silverman <bs@gauss.mitre.org> wrote:

Oh, my, Bob Silverman!  I'm in distinguished company.

>In article <1994Apr3.224626.13805@mnemosyne.cs.du.edu> colin@nyx10.cs.du.edu (Colin Plumb) writes:
>:Fast sieving for prime numbers
>: 
>:I've been working on efficient generation of "strong" primes.  That is,
>:primes where p-1 has a large prime factor.  You need to perform a similar
> 
>(1) Please define large.  Please tell us why you are concerned about whether
>    p-1 has a large prime factor. I suspect I know the reason. If my
>    suspicion is true, your concerns are not relevent.

What you suspect is partially true, which is that the old literature
all recommends it.  But the issue which brought it up for me was
DSS, which requires that 160-bit q divide 512-to-1024-bit p-1.

So I looked at PGP's "strong primes" code which does something similar and
thus came up with the terminology you saw.

(Someone else mentioned that the Blum, Blum and Shub generator
has certain properties only when (p-1)/2 and maybe (p-3)/4 are prime,
but I haven't double-checked that.  Some related thinking can be applied
to that case, but it's not the same.)

I had heard that it was unnecessary to bother with such testing these days
for RSA or discrete log primes, but thank you for confirming it so strongly.
Could I discuss it with you enough to understand it to the point where I
can explain it to others successfully?

> ECM renders the P-1 algorithm obsolete. And finding a "strong" prime
> by your definition does not protect from an ECM attack getting lucky.
> It is about as likely that an ECM attack will succeed as the chance that
> a random 100-digit prime can be found by P-1.

I'm sorry, but ECM?  Elliptic Curve something?

>It is possible to generate large primes very fast in such a way that
>you can prove they are prime very quickly. Take two moderate primes
>p and q [moderate means p is (say) 20-30 digits and q is ~80 digits].
>Now simply look at numbers of the form  rpq + 1  and rpq - 1 for small
>to moderate r. Consider only those r such that rpq + 1 and rpq -1 
>are not divisible by small primes. If you suspect one of these is prime,
>then it is trivial to construct a primality proof since you have a 
>complete factorization of p-1 or p+1.

Yes, I've heard of this.  Thank you for refershing my memory.

>If p ~ 20 digits and q ~80 digits isn't good enough, use slightly
>larger. The potential values of r which should be tried can be
>constructed as a wheel.
>

I have to translate everything into bits.  That's 70 bits and 270 bits.
Which provides primes up to 340 bits, or up to 380 assuming 30-digit
p and 10-bit r.  My stnadard benchmark is 512 bits for RSA and 1024
for Diffie-Hellman primes, so that's a bit small, but yes, I've seen
such techniques.  (Although I'm not sure on how to apply them based
on a factorization of p+1 rahter than p-1)

>:First of all, trial division by small primes is a very useful thing.
>:Basically, each prime p will weed out 1/p of the candidates.  If this
> 
>Negative. Each prime does NOT weed out 1/p. For example, if you sieve
>by 5, you must remember that 1/3 of the numbers you hit have already been
>sieved out by 3. The fraction is really: (1-1/2)(1-1/3)(1-1/5).....(1-1/p)
>By Mertens' theorem this is approximately exp(-gamma)/log p.

Um... yes, each prime does weed out 1/p.  That's what you wrote in
your equation and what I said, but maybe English is causing our
problems.  Each prime p weeds out 1/p of the numbers *which get that far*.
Testing by 3 passes 2/3 and testing by 5 passes 4/5, so testing by both
passes 8/15, which is what I meant.  I wanted the probability that, if
a number was a candidate prime being tested for divisibility by p, it
would be found divisible.  Since I'm assuming a non-parallel machine,
trial division will stop at that point.

>:can be done at a cost of about one multiply, it's significantly
>:thousand times faster than a Fermat test to the base 2, the cheapest
> 
>One is usually doing these divisions on multi-precise numbers. They
>are significantly more expensive than one multiply.

I was talking about doing one division first and then cacheing the
remainder to use in searching a range.  Again, I apologize if I confused
you with my discussion of trial division.  Trial division is the
*effect* I'm getting, but the implementation is much more efficient.

>:pseudo-primality test.
>: 
>:Obviously the smaller the prime, the more lucrative the trial division.
> 
>Secondly, even if one wants to do this, one should use a SIEVE, not
>trial division.

Um... I don't quite understand the distinction.  Obviously, the implementation
will be highly optimized, but from a mathematical point of view, it's
exactly equivalent to trial division.  If a sieve (and things like the
MPQS have convinced me that it's not obvious what the term means) is
something specific that is more efficient than trial division ==> If
trial division is implemented in such a way that it costs one single-
precision integer multiply per trial <==, then I'm *very* interested.

I asked, you may recall, if there was something more effective than trial
division but less expensive that a Fermat test to the base 2.

You can cut out some of the first trial divisions by, say, starting
on a multiple of 2*3*5*7 = 210 and using a table of the number relative
to that position that are divisible by none of the above (there are
1*2*4*6 = 48, so assuming you were clever enough the first time to
at least try only odd numbers, this eliminates testing for 35 numbers
in the range 1..209 which are divisible by 3, 14 of the remaining 70
which are divisible by 5, and 8 of the remaining 56 which are divisible
by 7, and bothering to test the remaining 48, so it saves 105+70+56 = 231
trial divisions per span of 210 numbers to search, or just over 2 trial
divisions per number tested the more naive way.  I'd have to do some
fiddling with the average number of trials per number to see just how
much of a saving that is.  Making use of the prime table itself for
this table (you have to add 1 and remove the low primes, but that's not
hard) would let you go up higher, since the table goes at least to
210*11 = 2310 and maybe 2310*13 = 30030.

Again, I emphasize that "trial division" does not describe the
implementation; after some precomputation (which essentially is a trial
division), the cost to attempt one division is one machine-word
multiplication.  I thought I described that technique.

Anyway, now that you've torn this parat, maybe you can take a crack
at my next piece on computing multiplicative inverses...

Thanks for your comments!
-- 
	-Colin
