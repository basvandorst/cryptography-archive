Path: msuinfo!agate!howland.reston.ans.net!vixen.cso.uiuc.edu!sdd.hp.com!nigel.msen.com!zib-berlin.de!news.dfn.de!news.dkrz.de!news.rrz.uni-hamburg.de!fbihh.informatik.uni-hamburg.de!bontchev
From: bontchev@fbihh.informatik.uni-hamburg.de (Vesselin Bontchev)
Newsgroups: comp.security.misc,alt.security,sci.crypt,alt.2600
Subject: Re: Jitec claim world's first virus-proof computer
Date: 25 Apr 1994 19:30:31 GMT
Organization: University of Hamburg -- Germany
Lines: 104
Message-ID: <2ph5on$9lp@rzsun02.rrz.uni-hamburg.de>
References: <2o3q7s$319@bmerha64.bnr.ca> <FAIGIN.94Apr8092012@solarium.aero.org> <FAIGIN.94Apr14081828@soldan.aero.org> <2olsn6$jb5@rzsun02.rrz.uni-hamburg.de> <1994Apr25.122529.1@thorium.rutgers.edu>
NNTP-Posting-Host: fbihh.informatik.uni-hamburg.de
X-Newsreader: TIN [version 1.2 PL2]
Xref: msuinfo comp.security.misc:9444 alt.security:15998 sci.crypt:26358 alt.2600:7754

leichter@thorium.rutgers.edu (leichter@thorium.rutgers.edu) writes:

> Suppose that the rules were the following:  No executing program may either
> (a) write to a file that has x permission for anyone; or (b) chmod any file to
> add x permission for anyone unless the owner of the executing program is (1)
> the same as the owner of the file being changed or (2) root.

Stoopid qvesion No. 1: how do you compile programs on such a system?

If the answer is "you don't, only root does", then this is not a
general-purpose system, I mean one that people would actually *use*.
If the answer is "the compiler is SUID (or the equivalent)", then here
is

Stoopid qvestion No. 2: how do you prevent a virus from outputting its
source in a file, calling the compiler to compile it, then executing
the resulting executable and so on? (or the many alternative
approaches, like renaming an existing executable and so on.)

> The exception
> clauses are (2) for trusted programs (particularly the linker);

Aha, so the something that turns sources into executables must be
SUID. Just as I expected.

> or (1) for
> changing your own files any way you like.

Yep. Too bad that when Bob runs Alice's infected program, this results
in the virus (running with Bob's privileges) creating a source of
itself (or copying it from Alice's directory, but the self-writing
programs are so cute that I just couldn't resist), compiling it with the 
SUID compiler/assembler/loader, and then executing it (still with Bob's 
privileges), thus infecting all of Bob's files.

> Under this semantics, when Bob runs Alice's infected program, the program is
> free to infect any of Alice's files - nothing new here, Alice could have
> infected her own files herself. 

Not really. When Bob runs Alice's virus, the virus runs with Bob's
privileges, and as funny as it is, *cannot* infect any of Alice's
programs. It can infect only Bob's, well, calling the compiler as a
middle step, if you use the improvements suggested by you.

> What it comes down to is that very few programs really need to create executa-
> ble files, almost none need to modify them - and one multi-user systems, the
> exceptions that involve creating or modifying *another user's* executable
> files are so rare that one can probably forbid them without causing undue
> harm.

Let's see... As a minimum, you need the linker (or you cannot compile
programs), the librarian (or a virus may infect the libraries), the
file manager (cp and all that jazz)... This idea reminds me of
something I read in a paper by Maria Pozzo, long time ago. The idea
was that you allow only to a few programs to modify/create executable
code and only if (a) they *create* it (as opposed to modifying
existing code) or (b) the names of the files containing it are
specified as arguments on the command line when invoking the program.
I remember that the idea was rejected as not good enough to stop
viruses, but I don't remember any more why... Probably will have to
re-read that paper...

> The result would be a system in which viruses could certainly spread as much
> as they liked within one person's files, but since the transitive closure of
> *executable* files writable by that person would be just that person's files,
> it could go no further.

Ah, yes, if you can achieve that (limiting the trnasitivity of the
information flow) - you have stopped the virus. However, such systems
tend to be either highly specialized or completely unusable (or both),
and I don't think that the solution proposed by you achieves it.

> Of course, no protection is absolute. 

Well, the OFF switch works pretty well... :-) Sorry, couldn't resist.

> (Ultimately, Alice might have hidden the virus in the source code and induced
> Bob to re-compile it himself!) 

Yep, that's what I meant, although in somehow more elaborated form.

> But one can still do a hell of a lot better than we are
> doing today.

One sure can. Even an out-of-the-box Un*x-ish system that has as many
holes as Swiss cheese can be much more virus-resitent than MessyDOS.
I was just trying to point out that viruses under such systems (and
even on much better protected ones) are still possible (something that
many non-MessyDOS users tend to forget) and that while you can do a
lot to make the problem easier to handle, you still cannot solve it
completely, without making the system unusable.

Other than that, and to return to the original subject that started
this (longish) tread - anybody who is marketing "virus-proof
computers" is almost certainly selling snake oil, unless they are of
the kind that you put in the microwave owens. :-)

Regards,
Vesselin
--
Vesselin Vladimirov Bontchev          Virus Test Center, University of Hamburg
Tel.:+49-40-54715-224, Fax: +49-40-54715-226      Fachbereich Informatik - AGN
< PGP 2.3 public key available on request. > Vogt-Koelln-Strasse 30, rm. 107 C
e-mail: bontchev@fbihh.informatik.uni-hamburg.de        22527 Hamburg, Germany
