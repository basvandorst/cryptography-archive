Path: msuinfo!agate!howland.reston.ans.net!news.moneng.mei.com!hookup!swrinde!elroy.jpl.nasa.gov!news.aero.org!faigin
From: faigin@aero.org (Daniel P. Faigin)
Newsgroups: comp.security.misc,alt.security,sci.crypt,alt.2600
Subject: Re: Jitec claim world's first virus-proof computer
Followup-To: comp.security.misc,alt.security,sci.crypt,alt.2600
Date: 11 Apr 1994 15:21:18 GMT
Organization: The Aerospace Corporation
Lines: 92
Message-ID: <FAIGIN.94Apr11082118@soldan.aero.org>
References: <2o3q7s$319@bmerha64.bnr.ca> <FAIGIN.94Apr8092012@solarium.aero.org>
	<2ob89e$c49@rzsun02.rrz.uni-hamburg.de>
NNTP-Posting-Host: soldan.aero.org
In-reply-to: bontchev@fbihh.informatik.uni-hamburg.de's message of 11 Apr 1994 10:20:30 GMT
Xref: msuinfo comp.security.misc:9172 alt.security:15774 sci.crypt:25841 alt.2600:6547

On 11 Apr 1994 10:20:30 GMT, bontchev@fbihh.informatik.uni-hamburg.de
(Vesselin Bontchev) said: 

> Sorry, I have to disagree. Almost all usable generic-purpose
> computers are infectable. The only ways to make viruses impossible is
> to do one of the following:

> 1) Limit functionality. If the computer is not programmable, it cannot
> be infected. You can't write a virus for a microwave oven.

> 2) Limit sharing. If any user on such a computer is *completely*
> isolated from any other user, then a virus can be written only by the
> user and it can infect only his/her programs. Note that making the
> computer just single-user is not enough - e.g. PCs are not
> virus-proof, because there is a way to share information between the
> different PC users (via diskettes, networks, modems).

> 3) Limit transitivity. If there is no way for a user B to pass to user
> C information that s/he has received from A, then a virus cannot
> spread. I think that most POset and Biba based protections rely on
> this principle.

You are correct (and I admit my error. That's what I get for posting from
home, quickly).

> An IBM PC-compatible machine is infectable even if
> it doesn't run MS-DOS. We've had several reports from IBM PC machines
> running Xenix being destroyed by Michelangelo on March 6. Boot sector
> viruses work on BIOS level and could care less about the operating
> system that is loaded afterwards. Indeed, most non-MS-DOS systems make
> them unable to spread, once the OS is loaded, but they can't prevent
> them from infecting the machine and/or causing damage at boot time.

But it is not the PC machine that does this; it is perfectly possible to
develop high-trust and high-assurance systems on the 286, 386, 486 and above
architecture. The original PC architecture might be more problematic. If the
privilege level mechanism and IOPL facility are used properly, user programs
(by definition running at a higher PL) cannot make unauthorized modifications
to various sectors, because the operating system or hardware will restrict
their actions. 

Unfortunately, most PC based systems do not provide such restrictions; and
thus systems based on those systems suffer from the problems.

> Yet Unix viruses are perfectly possible, we have three of them here,
> and some of the first viruses were created by Dr. Fred Cohen on a Unix
> system. Again Cohen has demonstrated that the Bell-LaPadula security
> model is unable to stop viruses.

However, I would contend that such viruses would be limited to infecting the
software of a single user, assuming a system is set up properly (e.g., proper
controls on setuid programs, correct restrictions on "root" programs, perhaps
the use of a SYSTEM MAC label to truly control the ability to write to ROOT
programs, etc.

> Dr. Faigin, I am really surprised to see you making such elementary
> mistakes.

First of all, I am not a Dr. (but thank you). As to mistakes -- I'd be worried
if I didn't make mistakes, for it shows that we are human and capable of
learning.  You are correct that I didn't analyze and rereview my first
response carefully before posting; and I welcome the corrections.

> This is correct, however. A computer that is based on the Biba
> integrity model should be virus-proof, because viruses are an
> integrity problem. However, I have yet to see an usable implementation
> of this model. Note that I am not saying that one is not possible or
> that one does not exist - just I have seen none yet. Hmm, when I think
> about it, I don't see how even a Biba model will prevent a virus from
> infecting the applications that run in the same integrity ring.

I have seen usable implementations of Biba, but you are correct; it shouldn't
solve the problem of viruses in the same integrity ring. DAC might help a
little there, but that still restricts the problem to a single user. What you
need is a combination of three access control basis:

	a) A mandatory policy ala Biba or something like that to isolate users
	   into rings. 
	b) A DAC policy based on identity to isolate problems to a single
	   user.
	c) A DAC policy based on program identity to program identity; that
 	   is, restricting access control based on the accessing program and
	   the accessed programs (for example, only the loader can modify .out
	   files, etc.)	 Note that even then, you would still be subject to
	   compiler attacks such as Dennis Ritchie described.

Daniel
--
[W]: The Aerospace Corp. M1/055 * POB 92957 * LA, CA 90009-2957 * 310/336-8228
[Email]:faigin@aero.org, faigin@acm.org         [Vmail]:310/336-5454 Box#68228
Seen on the net: "I always thought that 'Intel Inside' was a warning required
by Truth in Advertising laws..." 
