Path: msuinfo!agate!boojum.CS.Berkeley.EDU!nweaver
From: nweaver@boojum.CS.Berkeley.EDU (Nicholas C. Weaver)
Newsgroups: sci.crypt
Subject: Re: Quick crypt of compressed data
Date: 16 Apr 1994 09:00:43 GMT
Organization: University of California, Berkeley
Lines: 25
Message-ID: <2oo9fr$anl@agate.berkeley.edu>
References: <sv.766048428@id.dth.dk> <sv.766220553@id.dth.dk> <sv.766309898@id.dth.dk> <straitsCoCEpp.J74@netcom.com>
NNTP-Posting-Host: boojum.cs.berkeley.edu


	(I'm only commenting on a little part of this, which is more
information theoretic then cryptography related...)

In article <straitsCoCEpp.J74@netcom.com>,
Stewart C. Strait <straits@netcom.com> wrote:
>The vital point that seems to be overlooked here is that _all_ compression
>algorithms used on large volumes of text are _highly_ nonoptimal.

	From what I've learned in Information Theory so far, this is not the
case.  Universal Source Coding (such as Lempel-Ziv ) only become optimal
with large volumes of text.  These codes do not depend on the probability
distribution of the input, only that the distribution doesn't change (is
ergotic).  Thus, to compress _The Complete Works of William Shakespeare_,
L-Z will work very well, but to compress "Hello World", Lempel-Ziv will
inflate things consiterably.  Unix "compress" uses Lempel-Ziv.  

	(the only reason why I remember this is that we covered Universal
Source Coding and Lempel-Ziv in class on Thursday, and although I didn't
understand the proof of Lempel-Ziv's asymtopic optimality, I did understand
the rest of the lecture)
-- 
Nicholas C. Weaver			nweaver@orodruin.cs.berkeley.edu
        You know you are a techie when you use RCS on your writing.
                 I'm DUI on the Information Superhighway
