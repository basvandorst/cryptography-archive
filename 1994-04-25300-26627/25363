Path: msuinfo!agate!howland.reston.ans.net!europa.eng.gtefsd.com!MathWorks.Com!transfer.stratus.com!galt.sw.stratus.com!cme
From: cme@galt.sw.stratus.com (Carl Ellison)
Newsgroups: sci.crypt
Subject: Cryptanalysis of Huffman Codes (was Re: Encryption Using ...)
Date: 1 Apr 1994 18:14:34 GMT
Organization: Stratus Computer, Marlboro MA
Lines: 28
Message-ID: <2nhoaa$mlp@transfer.stratus.com>
References: <CnKDnt.3vr@chinet.chinet.com> <mpjCnL7I9.IIK@netcom.com>
NNTP-Posting-Host: galt.sw.stratus.com


The last time I did a Huffman code, I got about 2:1 compression.  That means
that I was left with an average of 4 bits per character.

Shannon estimated that English carries 1 bit per character of true entropy.

That leaves 3 bits per character of redundancy.

This will show up in the resulting Huffman code as repeated stretches of
bits, for repeated words.  In fact, every word you "encrypt" will have the
same bit string.  This identifies many word boundaries -- not all but many.

At this point, you have identified a code from some common words to bit
strings.  You need to start guessing words.  A trial Huffman code of
similar text will give you the approximate length of each letter.  From
that, you have the approximate length of each word in the language.

Once you have guessed a word, you start peeling off bits for the letters
in that word and trying those translations for initial letters of other
words you've identified.

It shouldn't take long at all to reconstruct the table.

-- 
 Carl M. Ellison                                     cme@sw.stratus.com
 RIPEM MD5OfPublicKey: 39D9860686A9F075A9A83D49589C677A
 Stratus Computer Inc.                               TEL: (508)460-2783
 55 Fairbanks Boulevard ; Marlborough MA 01752-1298  FAX: (508)624-7488
