Path: msuinfo!agate!ucbvax!hplabs!unix.sri.com!csl.sri.com!boucher
From: boucher@csl.sri.com (Peter K. Boucher)
Newsgroups: sci.crypt
Subject: Re: Encryption & Compression
Message-ID: <2p442eINN4nf@roche.csl.sri.com>
Date: 20 Apr 94 20:41:50 GMT
References: <CHAR-LEZ-190494085216@dnwmac194.globalvillag.com> <2p188q$1e8m@locutus.rchland.ibm.com> <CHAR-LEZ-200494114739@dnwmac194.globalvillag.com>
Organization: Computer Science Lab, SRI International
Lines: 25
NNTP-Posting-Host: redwood.csl.sri.com

In article <CHAR-LEZ-200494114739@dnwmac194.globalvillag.com>, CHAR-LEZ@globalvillag.com (Char-Lez Braden) writes:
|> 
|> So what you're really saying is, my inital understanding that with an
|> evenly distributed file, I should get no compression.  I have done lots of
|> work to show that with a truly random file, I do get compression.  Was my
|> testing flawed?

I need to know if the file was ``evenly distributed'' or ``truly random.''
If you have a sequence of bytes 0,1,...255,0,1,...255..., then it is
``evenly distributed'' but not ``truly random.''  How did you generate
the ``supposedly random'' files that you compressed?

Any good cryptosystem produces output that appears to be ``truly random.''
In fact, one crude test sometimes used is to try to compress the output
(if you can, it's not random).

If you've gat a compression algorithm that will compress normally-
distributed, ``truly random'' data, I'd like to have a look at it.

-- 
Peter K. Boucher
--
DISCLAIMER:  I am solely responsible for the contents of this message,
	     which should not be misconstrued as being in any way related
	     to the opinions of my employer.
