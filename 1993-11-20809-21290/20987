Path: msuinfo!agate!howland.reston.ans.net!vixen.cso.uiuc.edu!moe.ksu.ksu.edu!news
From: rcv@hobbes.ksu.ksu.edu (Rocke Verser)
Newsgroups: sci.crypt
Subject: Computer Shopper cipher challenge
Date: 10 Nov 1993 00:20:50 -0600
Organization: Kansas State University
Lines: 81
Distribution: world
Message-ID: <2bq182INNbfh@hobbes.ksu.ksu.edu>
NNTP-Posting-Host: hobbes.ksu.ksu.edu


Since no one else has posted any hard statistical analyses of the
Computer Shopper challenge, I offer the following summaries of
some analyses and hypotheses I have made.  [A much longer version
is available by e-mail on request, or I'll post if there is much
interest.]


Test 1:
  Classify each character of each file into one of two groups, "LO"
  (0x00-0x7F) and "HIGH" (0x80-0xFF).

  For SECRT1: Chi^2 value = 20.05; p(X<=20.05)=0.99999246

  (In other words a truly random sequence would produce a
  chi-squared value >= 20.05 less than once in 132,000 runs.)

  For SECRT2: Chi^2 value = 31.13; p(X<=31.13)=1-epsilon

  (My software could not accurately compute the probability since
  it was so close to one.)

Test 1 Conclusion:
  The files are definitely non-random.


Test 2:
  Hypothesize that the input files are ASCII (H/O bits known to be
  zero).

  Hypothesize that an average of 1 in nn plaintext characters survives
  unencrypted, while the remaining characters produce a truly random
  character in the ciphertext.

  Classify the ciphertext file in the same two groups as specified for
  Test 1. Compute the expected probability of a character in each of the
  two groups given the above two hypotheses.  Tabulate the Chi^2 value
  and p(X<=x) for various choices of nn.

  For SECRT1+SECRT2 combined:

  00-7F group:  11256 characters
  80-FF group:  10212 characters
        total:  21468 characters

   nn    x=Chi^2    p(X<=x)
  ----   -------   ---------
   16      4.15      95.83
   23      0.57      55.01
   24      1.04      69.29
   32      6.49      98.92

Test 2 Analysis:
  A fairly wide range of nn produces results that are statistically
  plausible.  The most likely choices of nn are in the high-teens to
  mid-20's.

  Suppose the algorithm performs some operation on m characters, the
  last of which survives unencrypted.  Then the algorithm chooses a new
  value, m', and repeats with another batch of m' characters.  If the
  programmer has selected m = 16 + rand(16), then the average value of m
  will be 23.5, which fits this model very well.

  Please note that I don't mean to suggest that this is THE algorithm
  the programmer of the challenge has chosen.  Rather, this is one
  possibility that seems to fit the statistical data.

Test 3:
  Some people have raised concern that the value of character 0xCC
  and/or 0xD0 is too high.

  This analysis is rather complex, so I will only summarize.  (Details
  are in the long version.)

  The character 0xCC does not appear more often than we would expect.

  The character 0xD0 does appear more often that we would expect, but
  not so much more often that we need to modify the model given in Test
  2 to account for it.

 -- Rocke Verser
