Path: msuinfo!netnews.upenn.edu!newsserver.jvnc.net!gmd.de!xlink.net!howland.reston.ans.net!usc!aja.rand.org!jim
From: jim@rand.org (Jim Gillogly)
Newsgroups: sci.crypt
Subject: Re: more computer shopper challenge
Date: 6 Nov 1993 19:25:51 GMT
Organization: Banzai Institute
Lines: 70
Distribution: world
Message-ID: <2bgtnv$mpm@aja.rand.org>
References: <752376077snx@netacsys.com>
NNTP-Posting-Host: mycroft.rand.org

Question: How many excess zeroes are there in the key stream?

The slightly-higher-than-random frequencies in 'SECRT1' and 'SECRT2' of
the space and etaoin-type characters suggests that more of the plaintext
characters are being encrypted with a zero key than a good RNG would
dictate, as several posters have pointed out.

I assume that the underlying text is ASCII rather than the suggested ZIP
or GIF or DOS FAT files, since the excess characters are the same ones
that would be high in English.  Somebody suggested it was simply
transposition; that's not what's going on, since the frequencies are not
much higher than random.

We should be able to estimate about how many characters are being passed
through directly, which may give us a handle on what error Stafford's
program is making to cause this regularity.  Here's one approach at
getting the estimate.

SECRT1 has 10325 characters, so if they were evenly distributed among the
256 characters we would expect 40 spaces (and 40 of everything else).  In
fact there are 119 spaces, for an excess of 79.  Using Jane Austen's
"Pride and Prejudice" as the standard (always a fine plan), we expect
16.70% spaces in text, so these 79 excess spaces would represent the
spaces out of a total of 473 plaintext characters encrypted with zeroes
(79 / 0.167).  This suggests that the key stream has one excess zero out
of every 22 bytes (10325 / 473).  Repeating this exercise for SECRT2 gives
one excess zero of every 17 bytes for that sample.

These estimates may be checked with the other high-frequency letters, to
see whether we get consistent estimates.  Here are the results for a few:

			Excess 0's
			per this
			many bytes
	Letter  E(freq) Sec1 Sec2

	space  16.70%   22   17
	   e    9.95%   20   26
	   t    6.64%   16   16
	   a    5.97%   25   20
	   o    5.78%   22   18
	   i    5.11%   14   22
	   n    5.43%   20   23
	   s    4.72%   38   19

		mean:   22   20

Perhaps one could get a better estimate by weighting these, or by taking
more letters, but the consistency is good enough to give some confidence
that we're in the right ball-park.

The implication is that about one out of 20-22 key bytes (give or take a
few) is a zero in excess of the expected 40.  If they were evenly spaced I
suspect they'd show up on as a high IC for one of the 22 (or 21 or 20 or
whatever) columns... higher than the .004's that I've seen on them,
anyway.  This appears not to be the case, so we're probably looking for a
non-cyclical modification of the algorithm with a built-in bug.

One example might be using the result of the previous encryption (or
plaintext) to decide how much to shift the pseudo-random number, which for
high values would result in shifting the good bits down the toilet.  Another
might be using a "% range" that depends on the previous character, but
which collapses to a range of 1 for about 1/20 of the trials.

So... more things to look at.  I note, of course, that this is not a fair
challenge, since the algorithm is unknown... somebody ought to send Stafford
a copy of the FAQ.
-- 
	Jim Gillogly
	Trewesday, 16 Blotmath S.R. 1993, 19:25
