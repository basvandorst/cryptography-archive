Path: msuinfo!netnews.upenn.edu!jvnc.net!yale.edu!qt.cs.utexas.edu!cs.utexas.edu!sun-barr!ames!agate!dog.ee.lbl.gov!ucbvax!virtualnews.nyu.edu!brnstnd
From: brnstnd@nyu.edu (Dan Bernstein)
Newsgroups: sci.crypt
Subject: A high-delay time-limited provably secure signature system
Message-ID: <11293.May206.52.1092@virtualnews.nyu.edu>
Date: 2 May 92 06:52:10 GMT
Organization: IR
Lines: 68

I have no idea whether or not this is new. It certainly violates some of
the basic assumptions behind ``classic'' signature systems, and it's not
immediately clear what types of cryptographic protocols can be adapted
to work with this. The system is extremely practical. It obviously works
just as well as a classic system for, e.g., the USENET sendsys
authentication problem, where delay is no big deal. Save this article---
you don't want someone patenting it.

Let h be a ``secure'' hash function. Alice picks an initial value v_500,
say, and computes v_{i-1} = h(v_i) down to v_0. Alice publishes v_0
together with the date ``January 1, 1995'' and the time interval ``one
day.''

Any time before January 2, 1995, Alice publishes M+1+h(M+v_1) for any
number of messages M. Here + denotes concatenation. Any time after
January 2, 1995, Alice publishes v_1. For h to be ``secure'' in this
application, it must not be possible to compute any new pair (M,h(M+v))
given any number of other such pairs (including the pair (empty,h(v)))
in reasonable time, for all but a statistically insignificant fraction
of ``bad'' v. (In particular it must not be possible to compute w with
h(w) = h(v) given only h(v). Note that the ``bad'' values must be
statistically insignificant not only within h's domain, but also within
the range of h and its first 500 iterates.)

Similarly, any time before January 3, 1995, Alice publishes M+2+h(M+v_2)
for any number of messages M. Any time after January 3, 1995, Alice
publishes v_2. And so on for each other v_i.

Imagine the situation of someone who receives message M+i+h(M+v_i)
before day i, then receives v_i. By assumption it is not possible for
anyone to compute v_i or M+i+h(M+v_i) from the values v_j with j < i. In
other words, nobody could have computed the given message using the
information Alice published before day i. Furthermore, after receiving
v_i, anyone can compute h(M+v_i) as well as h^i(v_i)=v_0. So each
message M carries the unforgeable signature of v_0. Note that there's no
problem with publications of fake v's since they'll simply be ignored.

We say that v_i ``expires'' on day i; it can only be used to sign
messages before it expires. This is a high-delay signature system
because a recipient has to remember each message until after the
associated v expires and is published. It is a time-limited signature
system because messages do not remain signed: someone who does not
receive a message before its v expires cannot verify its authenticity.
Alice can, of course, publish information anew with a later v. To extend
her signature past day 500 she can sign a message saying ``My new key
will be w_0 starting on <date>'' together with a reciprocating message
signed by w_0. Of course, someone who arrives on the scene more than 500
days later will never be able to verify anything signed by v_0.

Many variations on this scheme are possible. For example, instead of
v_{i-1} = h(v_i), we could set v_{i-1} = h(M_i+v_i) for various
information M_i initially kept secret. In practice the hash function
should be extensively parametrized, both to avoid accidental collisions
and to integrate useful information into each v_i. The delay between
expiration of v_i and v_{i+1} could be made to depend upon i, though
there are no obvious advantages in doing so.

As mentioned above, it's not obvious which cryptographic protocols can
be adapted to this situation. The above signature system assumes at a
critical juncture that recipients have _memory_, and also assumes a
common time frame---realistic but unusual in public-key cryptography.
What can be done about repudiation of signatures? Or broken keys? Is
there any advantage to a public-key center with this system? What
expiration intervals are appropriate, and why? Should 500 be made very
low, to enforce rapid key change and speed up v_i computation, or very
high, to encourage use of keys as long-term identities?

---Dan
