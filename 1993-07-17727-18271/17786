Newsgroups: sci.crypt
Path: msuinfo!agate!howland.reston.ans.net!noc.near.net!uunet!destroyer!cs.ubc.ca!unixg.ubc.ca!acs.ucalgary.ca!cpsc.ucalgary.ca!jamesm
From: jamesm@cpsc.ucalgary.ca (Mark James)
Subject: Re: Cryptanalysis of Compressed Text
In-Reply-To: C445585@mizzou1.missouri.edu's message of Fri, 02 Jul 93 22:33:28 CDT
Message-ID: <JAMESM.93Jul4172636@do.cpsc.ucalgary.ca>
Sender: news@cpsc.ucalgary.ca (News Manager)
Organization: The University of Calgary
References: <20sk9bINNkcv@twain.ucs.umass.edu> <16BFF13D3E.C445585@mizzou1.missouri.edu>
Date: Mon, 5 Jul 1993 00:26:36 GMT
Lines: 25

In article <16BFF13D3E.C445585@mizzou1.missouri.edu> C445585@mizzou1.missouri.edu (John Kelsey) writes:
      Boyd also says that the best compression scheme he tried compressed
   technical English down to 2.25 bits per character.  I've seen the figure
   of 1 bit per character bounced around as the likely real information content
   of English, but I've never seen a good argument for why that's the case.

This figure comes from Shannon's experiments on the entropy of English text.
His experiment was basicly to have people guess at letters from an English
sentence, and measure how accuratly they could do so.  Compressors can't do as
well as humans because humans have much much better models of English.

Shannon's work is presented in:

C.E. Shannon and W. Weaver, The Mathematical Theory of Communication.
University of Illinois Press, 1949.

C.E. Shannon, "Prediction and Entropy of Printed English", Bell Systems
Technical Journal. 30 (Jan 1951) pp. 50-64

     M.


--
Mark James
jamesm@cpsc.ucalgary.ca
